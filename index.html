<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<link rel="icon" href="favicon.ico" type="image/x-icon">

  <head>

    <script src="js/head.js"></script>
    <meta name="description" content="Yisen Wang is an Assistant Professor at Peking University">
    <title>Yisen Wang @ Peking University</title>

    <link rel="stylesheet" href="css/font.css">
    <link rel="stylesheet" href="css/main.css">

<script>
var scripts = document.getElementsByTagName('script');
var myScript = scripts[scripts.length - 1];

var queryString = myScript.src.replace(/^[^\?]+\??/, '');

var params = parseQuery(queryString);

var recruit = 0;

function parseQuery(query) {
    var Params = {};
    if (!query) return Params; // return empty object
    var Pairs = query.split(/[;&]/);
    for (var i = 0; i < Pairs.length; i++) {
        var KeyVal = Pairs[i].split('=');
        if (!KeyVal || KeyVal.length != 2) continue;
        var key = unescape(KeyVal[0]);
        var val = unescape(KeyVal[1]);
        val = val.replace(/\+/g, ' ');
        Params[key] = val;
    }
    return Params;
}

function showPubs(id) {
    if (id == 0) {
        // Recent: 根据自定义的 recent 类来展示论文
        var recent = document.getElementsByClassName('recent');
        var temp = "<div class=\"text anchor\">&nbsp;</div>";
        var prefix = "<div class=\"publication\">";
        var suffix = "</div>";
        for (var i = 0; i < recent.length; i++){
            temp += prefix + recent[i].innerHTML + suffix;
        }
        document.getElementById('pubs').innerHTML = temp;
        document.getElementById('select0').style = 'text-decoration:underline;color:#000000';
        document.getElementById('select1').style = '';
        document.getElementById('select2').style = '';
        document.getElementById('select3').style = '';
    } else if (id == 1) {
        // Selected: 和原来一样，展示所有具有 selected 类的论文
        var selected = document.getElementsByClassName('selected');
        var temp = "<div class=\"text anchor\">&nbsp;</div>";
        var prefix = "<div class=\"publication\">";
        var suffix = "</div>";
        for (var i = 0; i < selected.length; i++){
            temp += prefix + selected[i].innerHTML + suffix;
        }
        document.getElementById('pubs').innerHTML = temp;
        document.getElementById('select1').style = 'text-decoration:underline;color:#000000';
        document.getElementById('select0').style = '';
        document.getElementById('select2').style = '';
        document.getElementById('select3').style = '';
    } else if (id == 2) {
        // All by date: 和原来一样，根据年份数组遍历展示
        var years = ["Preprint", "2025", "2024", "2023", "2022", "2021", "2020", "2019", "2018"];
        var html = "";
        for (var k = 0; k < years.length; k++){
            var year = years[k];
            var selected = document.getElementsByClassName(year);
            var temp = "<div class=\"text anchor\"><h4>" + year + "</h4></div>";
            var prefix = "<div class=\"publication\">";
            var suffix = "</div>";
            for (var i = 0; i < selected.length; i++){
                temp += prefix + selected[i].innerHTML + suffix;
            }
            html += temp;
        }
        document.getElementById('pubs').innerHTML = html;
        document.getElementById('select2').style = 'text-decoration:underline;color:#000000';
        document.getElementById('select0').style = '';
        document.getElementById('select1').style = '';
        document.getElementById('select3').style = '';
    } else if (id == 3) {
        // All by topic: 和原来一样，根据主题展示论文
        var topics = ["SSL", "Adv", "Rea", "Graph"];
        var html = "";
        for (var k = 0; k < topics.length; k++){
            var topic = topics[k];
            var topic_fullname = document.getElementById("_" + topic).innerHTML;
            var selected = document.getElementsByClassName(topic);
            var temp = "<div class=\"text anchor\" id=\"" + topic + "\"><h4>" + topic_fullname + "</h4></div>";
            var prefix = "<div class=\"publication\">";
            var suffix = "</div>";
            for (var i = 0; i < selected.length; i++){
                temp += prefix + selected[i].innerHTML + suffix;
            }
            html += temp;
        }
        document.getElementById('pubs').innerHTML = html;
        document.getElementById('select3').style = 'text-decoration:underline;color:#000000';
        document.getElementById('select0').style = '';
        document.getElementById('select1').style = '';
        document.getElementById('select2').style = '';
    }
}


function togglebib(paperid)
{
    var paper = document.getElementById(paperid) ;
    var bib = paper.getElementsByTagName('pre') ;
    var link = paper.getElementsByTagName('a') ;
    if (bib.length > 0) {
        if (bib[0].style.display == 'none') {
            //console.log(document.body.clientWidth);
            width = document.body.clientWidth - 100;
            bib[0].style.maxWidth = width + 'px';
            bib[0].style.display = 'block' ;
            //bib[0].style.textDecoration = 'underline';
            link[link.length - 1].style.textDecoration = 'underline';
        } else {
            bib[0].style.display = 'none' ;
            bib[0].style.textDecoration = 'none';
            link[link.length - 1].style.textDecoration = 'none';
        }
    }
}

</script>

    <script src="js/scroll.js"></script>

  </head>

  <body>

    <div class="outercontainer">
      

        <div class="container body">

        <div class="content heading anchor" id="home">
          <div class="img"><img class="img_responsive" src="./talk-photo-2.jpg" alt="Photo"></div>
          <div class="text info">
            <h1>Yisen Wang</h1>
            <p/>
            <div>Assistant Professor, Ph.D. Advisor</div>
            <div>School of Intelligence Science and Technology</div>
            <div>Peking University</div>
            <div>Email: yisen.wang AT pku DOT edu.cn</div>
            <p/>
            <span>[<a href="https://scholar.google.com/citations?user=uMWPDboAAAAJ&amp;hl=en" target="_blank">Google Scholar</a>]</span>
            <span>[<a href="https://github.com/orgs/PKU-ML/repositories" target="_blank">Github</a>]</span>
            <span>[<a href="https://www.cis.pku.edu.cn/info/1362/2264.htm" target="_blank">PKU Homepage</a>]</span>
            <p/>
            <p/>
            <span>[<a href="students.html">Students</a>]</span>
            <span>[<a href="recruit.html">Recruitment Instructions</a>]</span>
            <p/>
          </div>
          <div class="text topic">
            <p/>
            <div class="title">Research Topics</div>
            <ul>
              <li><a id="_SSL" href="#SSL" onclick="showPubs(3)">Theory of Learning Paradigm</a></li>
              <li><a id="_Adv" href="#Adv" onclick="showPubs(3)">AI Safety</a></li>
              <li><a id="_Rea" href="#Rea" onclick="showPubs(3)">Reasoning in LLMs</a></li>
<!--              <li><a id="_OOD" href="#OOD" onclick="showPubs(2)">Out-of-Distribution Generalization</a></li>-->
<!--              <li><a id="_WSL" href="#WSL" onclick="showPubs(2)">Weakly-Supervised Learning</a></li>-->
              <li><a id="_Graph" href="#Graph" onclick="showPubs(3)">Graph Learning</a></li>
<!--              <li><a id="_SNN" href="#SNN" onclick="showPubs(2)">Spiking Neural Network</a></li>-->
            </ul>
            <p/>
          </div>
          <div class="text">
            <p style="text-align: justify;">I am now a Tenure-track Assistant Professor (Ph.D. Advisor) at <a href="https://www.pku.edu.cn/">Peking University</a>.
              I am also a faculty member of <a href="https://zero-lab-pku.github.io/people/" target="_blank">ZERO Lab</a> led by <a href="https://zhouchenlin.github.io/" target="_blank">Prof. Zhouchen Lin</a>.
              I got my Ph.D. degree from <a href="http://www.cs.tsinghua.edu.cn/">Department of Computer Science and Technology</a>, <a href="https://www.tsinghua.edu.cn/">Tsinghua University</a>.
              I have visited <a href="https://www.gatech.edu/">Georgia Tech</a>, USA, hosted by <a href="https://scholar.google.com/citations?user=Xl4E0CsAAAAJ&hl=en" target="_blank">Prof. Le Song</a> and <a href="https://www.cc.gatech.edu/~zha/" target="_blank">Prof. Hongyuan Zha</a>, and <a href="https://www.unimelb.edu.au/">The University of Melbourne</a>, Australia, hosted by <a href="https://people.eng.unimelb.edu.au/baileyj/" target="_blank">Prof. James Bailey</a>.
            </p>

            <p style="text-align: justify;">My research centers on <span style="color: blue;"><strong>Representation Learning</strong></span>, with a focus on deriving meaningful and robust representations from diverse data types--including unlabeled, noisy, and adversarial data--grounded in principled and theoretically driven methodologies.
              Specifically, we recently focus on <span style="color: blue;"><strong>Theoretical and Algorithmic Foundations of LLMs</strong></span> (e.g., Self-Supervised/Weakly-Supervised Learning, In-context Learning, Length Generalization, and Reasoning) and <span style="color: blue;"><strong>AI Safety</strong></span> (ensuring Trustworthy and Reliable AI Systems).
            </p>

            <p style="text-align: justify;">We have received the <strong><a href="https://2021.ecmlpkdd.org/index.html@p=2148.html" target="_blank">Best Paper Award</a> of ECML-PKDD 2021</strong>, <strong><a href="https://iclworkshop.github.io/" target="_blank">Best Paper Award</a> of ICML 2024 Workshop</strong>, <strong><a href="https://advml-workshop.github.io/icml2021/" target="_blank">Silver Best Paper Award</a> of ICML 2021 Workshop</strong>,
              <strong><a href="https://ml.cs.tsinghua.edu.cn/adv-bench/#/" target="_blank">1st Place</a> in the CVPR 2021 Adversarial Competitions</strong>, and <strong><a href="http://hof.geekpwn.org/zh/index.html" target="_blank">Champion</a> in the 2020 GeekPwn CAAD Competitions</strong>.
              We are also lucky to win the <strong><a href="https://www.cis.pku.edu.cn/info/1082/2638.htm" target="_blank">First Prize</a> in the 22nd Teaching Competition of Peking University</strong>, <strong>Beijing Nova Talent Program</strong>, <strong>ACM Beijing Rising Star Award</strong>, <strong>Notable Area Chair at NeurIPS</strong>, and <strong>World's Top 2% Scientists</strong>.
            </p>
          </div>
        </div>


        <div class="content front">
          <div class="text">
            <h3 style="margin-bottom:.5em; text-align:justify">Openings</h3>
            <ul>
              <li><strong>We are always actively recruiting highly motivated Postdocs, Ph.D. students and Interns! For Prospective applicants, please read this <a href="recruit.html" style="color: red;">Instructions</a> for recruiting information, and <a href="https://csrankings.org/#/fromyear/2020/toyear/2024/index?mlmining&cn" target="_blank">CSRankings</a> for ranking information!</strong></li>
            </ul>
          </div>
        </div>

        <div class="content front">
          <div class="text">
            <h3 style="margin-bottom:.5em; text-align:justify">News</h3>
            <ul>
              <li>2024.12, My PhD student won the CAA Outstanding Ph.D. Dissertation Award!</li>
              <li>2024.6, We released <a href="https://github.com/PKU-ML/ISSLLib" target="_blank"><strong>Interpretable Self-Supervised Learning Library</strong></a> to cover all interpretable-related algorithms of our group!</li>
              <li>2024.5, We released <a href="https://github.com/PKU-ML/TMLlib" target="_blank"><strong>Trustworthy Machine Learning Library</strong></a> to cover all trustworthy-related algorithms of our group!</li>
              <li>2024.4, Our jailbreaking work (<a href="https://arxiv.org/abs/2310.06387" target="_blank">In-context Attack</a>) has been featured and scaled up by <a href="https://www.anthropic.com/research/many-shot-jailbreaking" target="_blank">Anthropic</a> (Claude 3 Group)!</li>
              <li>2024.3, My PhD student won the CAAI Outstanding Ph.D. Dissertation Runner-Up Award!</li>
              <li>2024.2, My supervised undergraduate student was admitted to the PhD program of UC Berkeley!</li>
            </ul>
          </div>
        </div>

        <div class="content anchor" id="publications">
          <div class="text front">
            <h3 style="margin-bottom:0em">
              Publications 
                (<a href="" id="select0" onclick="showPubs(0); return false;">Recent</a> /
                 <a href="" id="select1" onclick="showPubs(1); return false;">Selected</a> /
                 <a href="" id="select2" onclick="showPubs(2); return false;">All by date</a> /
                 <a href="" id="select3" onclick="showPubs(3); return false;">All by topic</a>)
            </h3>
            <span class="tag">(* Equal  Contribution and # Corresponding  Author)</span>
          </div>
          
          <div id="pubs"></div>

    
            <div id="all_pubs" style="display:none">

              <div class="recent Preprint Rea">
              <div class="text" id="mo2024fight">
              <ul>
                <li><strong>When More is Less: Understanding Chain-of-Thought Length in LLMs</strong><br>
                Yuyang Wu, Yifei Wang, Tianqi Du, Stefanie Jegelka, <strong>Yisen Wang#</strong><br>
                <em><strong>Preprint</strong></em> <strong><font color="#ff0000"></font></strong><br>
                [<a href="https://arxiv.org/pdf/2502.07266" target="_blank">PDF</a>]
                [<a href="" target="_blank">Code</a>]
                [<a href="javascript:togglebib('mo2024fight')">Bib</a>]<br>
                <pre style="display: none">

                </pre>
              </li>
              </ul>
              </div>
            </div>


              <div class="recent Preprint Rea">
              <div class="text" id="li2025smarter">
              <ul>
                <li><strong>Are Smarter LLMs Safer? Exploring Safety-Reasoning Trade-offs in Prompting and Fine-Tuning</strong><br>
                Ang Li, Yichuan Mo, Mingjie Li, Yifei Wang, <strong>Yisen Wang#</strong><br>
                <em><strong>Preprint</strong></em> <strong><font color="#ff0000"></font></strong><br>
                [<a href="https://arxiv.org/pdf/2502.09673" target="_blank">PDF</a>]
                [<a href="" target="_blank">Code</a>]
                [<a href="javascript:togglebib('li2025smarter')">Bib</a>]<br>
                <pre style="display: none">
                          @article{li2025smarter,
                            title={Are Smarter LLMs Safer? Exploring Safety-Reasoning Trade-offs in Prompting and Fine-Tuning},
                            author={Li, Ang and Mo, Yichuan and Li, Mingjie and Wang, Yifei and Wang, Yisen},
                            journal={arXiv preprint arXiv:2502.09673},
                            year={2025}
                          }
                </pre>
              </li>
              </ul>
              </div>
            </div>


              <div class="recent selected 2025 SSL Rea">
              <div class="text" id="fang2025what">
              <ul>
                <li><strong>What is Wrong with Perplexity for Long-context Language Modeling?</strong><br>
                Lizhe Fang, Yifei Wang, Zhaoyang Liu, Chenheng Zhang, Stefanie Jegelka, Jinyang Gao, Bolin Ding, <strong>Yisen Wang#</strong><br>
                <em><strong>ICLR 2025</strong></em> <strong style="color: red;">(New Reliable Metric for Long-context LLMs)</strong><br>
                [<a href="https://openreview.net/pdf?id=fL4qWkSmtM" target="_blank">PDF</a>]
                [<a href="https://github.com/PKU-ML/LongPPL" target="_blank">Code</a>]
                [<a href="javascript:togglebib('fang2025what')">Bib</a>]<br>
                <pre style="display: none">
                            @inproceedings{fang2025what,
                            title={What is Wrong with Perplexity for Long-context Language Modeling?},
                            author={Lizhe Fang and Yifei Wang and Zhaoyang Liu and Chenheng Zhang and Stefanie Jegelka and Jinyang Gao and Bolin Ding and Yisen Wang},
                            booktitle={ICLR},
                            year={2025}
                            }
                </pre>
              </li>
              </ul>
              </div>
            </div>

              <div class="2025 SSL Rea">
              <div class="text" id="fang2025rethinking">
              <ul>
                <li><strong>Rethinking Invariance in In-context Learning</strong><br>
                Lizhe Fang, Yifei Wang, Khashayar Gatmiry, Lei Fang, <strong>Yisen Wang#</strong><br>
                <em><strong>ICLR 2025</strong></em> <strong><font color="#ff0000"></font></strong><br>
                [<a href="https://openreview.net/pdf?id=q1UyoY3MgJ" target="_blank">PDF</a>]
                [<a href="https://github.com/PKU-ML/InvICL" target="_blank">Code</a>]
                [<a href="javascript:togglebib('fang2025rethinking')">Bib</a>]<br>
                <pre style="display: none">
                          @inproceedings{fang2025rethinking,
                          title={Rethinking Invariance in In-context Learning},
                          author={Lizhe Fang and Yifei Wang and Khashayar Gatmiry and Lei Fang and Yisen Wang},
                          booktitle={ICLR},
                          year={2025}
                          }
                </pre>
              </li>
              </ul>
              </div>
            </div>

              <div class="recent selected 2025 SSL Rea">
              <div class="text" id="wang2025can">
              <ul>
                <li><strong>Can In-context Learning Really Generalize to Out-of-distribution Tasks?</strong><br>
                Qixun Wang, Yifei Wang, Xianghua Ying#, <strong>Yisen Wang#</strong><br>
                <em><strong>ICLR 2025</strong></em> <strong><font color="#ff0000"></font></strong><br>
                [<a href="https://openreview.net/pdf?id=INe4otjryz" target="_blank">PDF</a>]
                [<a href="https://github.com/NOVAglow646/ICL-OOD" target="_blank">Code</a>]
                [<a href="javascript:togglebib('wang2025can')">Bib</a>]<br>
                <pre style="display: none">
                          @inproceedings{wang2025can,
                          title={Can In-context Learning Really Generalize to Out-of-distribution Tasks?},
                          author={Qixun Wang and Yifei Wang and Xianghua Ying and Yisen Wang},
                          booktitle={ICLR},
                          year={2025}
                          }
                </pre>
              </li>
              </ul>
              </div>
            </div>

              <div class="selected 2025 SSL Rea">
              <div class="text" id="ouyang2025projection">
              <ul>
                <li><strong>Projection Head is Secretly an Information Bottleneck</strong><br>
                Zhuo Ouyang, Kaiwen Hu, Qi Zhang, Yifei Wang, <strong>Yisen Wang#</strong><br>
                <em><strong>ICLR 2025</strong></em> <strong><font color="#ff0000"></font></strong><br>
                [<a href="https://openreview.net/pdf?id=L0evcuybH5" target="_blank">PDF</a>]
                [<a href="https://github.com/PKU-ML/Projector_Theory" target="_blank">Code</a>]
                [<a href="javascript:togglebib('ouyang2025projection')">Bib</a>]<br>
                <pre style="display: none">
                            @inproceedings{ouyang2025projection,
                            title={Projection Head is Secretly an Information Bottleneck},
                            author={Zhuo Ouyang and Kaiwen Hu and Qi Zhang and Yifei Wang and Yisen Wang},
                            booktitle={ICLR},
                            year={2025}
                            }
                </pre>
              </li>
              </ul>
              </div>
            </div>

              <div class="recent selected 2025 Adv">
              <div class="text" id="li2025salora">
              <ul>
                <li><strong>SaLoRA: Safety-Alignment Preserved Low-Rank Adaptation</strong><br>
                Mingjie Li, Wai Man Si, Michael Backes, Yang Zhang, <strong>Yisen Wang#</strong><br>
                <em><strong>ICLR 2025</strong></em> <strong><font color="#ff0000"></font></strong><br>
                [<a href="https://openreview.net/pdf?id=GOoVzE9nSj" target="_blank">PDF</a>]
                [<a href="https://github.com/homles11/SaLoRA" target="_blank">Code</a>]
                [<a href="javascript:togglebib('li2025salora')">Bib</a>]<br>
                <pre style="display: none">
                            @inproceedings{li2025salora,
                            title={SaLo{RA}: Safety-Alignment Preserved Low-Rank Adaptation},
                            author={Mingjie Li and Wai Man Si and Michael Backes and Yang Zhang and Yisen Wang},
                            booktitle={ICLR},
                            year={2025}
                            }
                </pre>
              </li>
              </ul>
              </div>
            </div>

              <div class="selected 2025 SSL Adv">
              <div class="text" id="zhang2025beyond">
              <ul>
                <li><strong>Beyond Interpretability: The Gains of Feature Monosemanticity on Model Robustness</strong><br>
                Qi Zhang, Yifei Wang, Jingyi Cui, Xiang Pan, Qi Lei, Stefanie Jegelka, <strong>Yisen Wang#</strong><br>
                <em><strong>ICLR 2025</strong></em> <strong><font color="#ff0000"></font></strong><br>
                [<a href="https://openreview.net/pdf?id=g6Qc3p7JH5" target="_blank">PDF</a>]
                [<a href="https://github.com/PKU-ML/Monosemanticity-Robustness" target="_blank">Code</a>]
                [<a href="javascript:togglebib('zhang2025beyond')">Bib</a>]<br>
                <pre style="display: none">
                            @inproceedings{zhang2025beyond,
                            title={Beyond Interpretability: The Gains of Feature Monosemanticity on Model Robustness},
                            author={Qi Zhang and Yifei Wang and Jingyi Cui and Xiang Pan and Qi Lei and Stefanie Jegelka and Yisen Wang},
                            booktitle={ICLR},
                            year={2025}
                            }
                </pre>
              </li>
              </ul>
              </div>
            </div>

              <div class="selected 2025 SSL Rea">
              <div class="text" id="yan2025tcmoe">
              <ul>
                <li><strong>TC-MoE: Augmenting Mixture of Experts with Ternary Expert Choice</strong><br>
                Shen Yan, Xingyan Bin, Sijun Zhang, <strong>Yisen Wang#</strong>, Zhouchen Lin#<br>
                <em><strong>ICLR 2025</strong></em> <strong><font color="#ff0000"></font></strong><br>
                [<a href="https://openreview.net/pdf?id=dsP91M4hDL" target="_blank">PDF</a>]
                [<a href="https://github.com/stiger1000/TC-MoE" target="_blank">Code</a>]
                [<a href="javascript:togglebib('yan2025tcmoe')">Bib</a>]<br>
                <pre style="display: none">
                            @inproceedings{yan2025tcmoe,
                            title={{TC}-MoE: Augmenting Mixture of Experts with Ternary Expert Choice},
                            author={Shen Yan and Xingyan Bin and Sijun Zhang and Yisen Wang and Zhouchen Lin},
                            booktitle={ICLR},
                            year={2025}
                            }
                </pre>
              </li>
              </ul>
              </div>
            </div>

              <div class="2025 SSL">
              <div class="text" id="peng2025leveraging">
              <ul>
                <li><strong>Leveraging Flatness to Improve Information-Theoretic Generalization Bounds for SGD</strong><br>
                Ze Peng, Jian Zhang, <strong>Yisen Wang</strong>, Lei Qi, Yinghuan Shi, Yang Gao<br>
                <em><strong>ICLR 2025</strong></em> <strong><font color="#ff0000"></font></strong><br>
                [<a href="https://openreview.net/pdf?id=pSdE7PIA64" target="_blank">PDF</a>]
<!--                [<a href="" target="_blank">Code</a>]-->
                [<a href="javascript:togglebib('peng2025leveraging')">Bib</a>]<br>
                <pre style="display: none">
                          @inproceedings{peng2025leveraging,
                          title={Leveraging Flatness to Improve Information-Theoretic Generalization Bounds for {SGD}},
                          author={Ze Peng and Jian Zhang and Yisen Wang and Lei Qi and Yinghuan Shi and Yang Gao},
                          booktitle={ICLR},
                          year={2025}
                          }
                </pre>
              </li>
              </ul>
              </div>
            </div>



            <div class="selected 2024 SSL Rea">
              <div class="text" id="wang2024a">
              <ul>
                <li><strong>A Theoretical Understanding of Self-Correction through In-context Alignment</strong><br>
                Yifei Wang, Yuyang Wu, Zeming Wei, Stefanie Jegelka, <strong>Yisen Wang#</strong><br>
                <em><strong>NeurIPS 2024</strong></em> <strong><font color="#ff0000">(Best Paper Award at ICML 2024 Workshop on In-Context Learning)</font></strong><br>
                [<a href="https://openreview.net/pdf?id=OtvNLTWYww" target="_blank">PDF</a>]
                [<a href="https://github.com/yifeiwang77/Self-Correction" target="_blank">Code</a>]
                [<a href="https://mp.weixin.qq.com/s/W-YOehfVSRlYIBlg8itnBg" target="_blank">Featured by Synced</a>]
                [<a href="javascript:togglebib('wang2024a')">Bib</a>]<br>
                <pre style="display: none">
                    @inproceedings{wang2024a,
                            title={A Theoretical Understanding of Self-Correction through In-context Alignment},
                            author={Yifei Wang and Yuyang Wu and Zeming Wei and Stefanie Jegelka and Yisen Wang},
                            booktitle={NeurIPS},
                            year={2024}
                            }
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="selected 2024 Adv">
              <div class="text" id="mo2024fight">
              <ul>
                <li><strong>Fight Back Against Jailbreaking via Prompt Adversarial Tuning</strong><br>
                Yichuan Mo, Yuji Wang, Zeming Wei, <strong>Yisen Wang#</strong><br>
                <em><strong>NeurIPS 2024</strong></em> <strong><font color="#ff0000"></font></strong><br>
                [<a href="https://openreview.net/pdf?id=nRdST1qifJ" target="_blank">PDF</a>]
                [<a href="https://github.com/PKU-ML/PAT" target="_blank">Code</a>]
                [<a href="javascript:togglebib('mo2024fight')">Bib</a>]<br>
                <pre style="display: none">
                        @inproceedings{mo2024fight,
                        title={Fight Back Against Jailbreaking via Prompt Adversarial Tuning},
                        author={Yichuan Mo and Yuji Wang and Zeming Wei and Yisen Wang},
                        booktitle={NeurIPS},
                        year={2024}
                        }
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="2024 Graph">
              <div class="text" id="ma2024a">
              <ul>
                <li><strong>A Canonization Perspective on Invariant and Equivariant Learning</strong><br>
                Jiangyan Ma, Yifei Wang, Derek Lim, Stefanie Jegelka, <strong>Yisen Wang#</strong><br>
                <em><strong>NeurIPS 2024</strong></em> <strong><font color="#ff0000"></font></strong><br>
                [<a href="https://openreview.net/pdf?id=jjcY92FX4R" target="_blank">PDF</a>]
                [<a href="https://github.com/PKU-ML/canonicalization" target="_blank">Code</a>]
                [<a href="javascript:togglebib('ma2024a')">Bib</a>]<br>
                <pre style="display: none">
                            @inproceedings{ma2024a,
                            title={A Canonicalization Perspective on Invariant and Equivariant Learning},
                            author={George Ma and Yifei Wang and Derek Lim and Stefanie Jegelka and Yisen Wang},
                            booktitle={NeurIPS},
                            year={2024}
                            }
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="2024 Graph">
              <div class="text" id="wang2024dissecting">
              <ul>
                <li><strong>Dissecting the Failure of Invariant Learning on Graphs</strong><br>
                Qixun Wang, Yifei Wang, <strong>Yisen Wang#</strong>, Xianghua Ying<br>
                <em><strong>NeurIPS 2024</strong></em> <strong><font color="#ff0000"></font></strong><br>
                [<a href="https://openreview.net/pdf?id=7eFS8aZHAM" target="_blank">PDF</a>]
                [<a href="https://github.com/NOVAglow646/NeurIPS24-Invariant-Learning-on-Graphs" target="_blank">Code</a>]
                [<a href="javascript:togglebib('wang2024dissecting')">Bib</a>]<br>
                <pre style="display: none">
                          @inproceedings{wang2024dissecting,
                          title={Dissecting the Failure of Invariant Learning on Graphs},
                          author={Qixun Wang and Yifei Wang and Yisen Wang and Xianghua Ying},
                          booktitle={NeurIPS},
                          year={2024}
                          }
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="2024 SSL">
              <div class="text" id="wang2024understanding">
              <ul>
                <li><strong>Understanding the Role of Equivariance in Self-supervised Learning</strong><br>
                Yifei Wang, Kaiwen Hu, Sharut Gupta, Ziyu Ye, <strong>Yisen Wang</strong>, Stefanie Jegelka<br>
                <em><strong>NeurIPS 2024</strong></em> <strong><font color="#ff0000"></font></strong><br>
                [<a href="https://openreview.net/pdf?id=NLqdudgBfy" target="_blank">PDF</a>]
                [<a href="https://github.com/kaotty/Understanding-ESSL" target="_blank">Code</a>]
                [<a href="javascript:togglebib('wang2024understanding')">Bib</a>]<br>
                <pre style="display: none">
                          @inproceedings{wang2024understanding,
                          title={Understanding the Role of Equivariance in Self-supervised Learning},
                          author={Yifei Wang and Kaiwen Hu and Sharut Gupta and Ziyu Ye and Yisen Wang and Stefanie Jegelka},
                          booktitle={NeurIPS},
                          year={2024}
                          }
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="selected 2024 SSL">
              <div class="text" id="zhang2024look">
              <ul>
                <li><strong>Look Ahead or Look Around? A Theoretical Comparison Between Autoregressive and Masked Pretraining</strong><br>
                Qi Zhang, Tianqi Du, Haotian Huang, Yifei Wang, <strong>Yisen Wang#</strong><br>
                <em><strong>ICML 2024</strong></em> <span style="color: red;"><strong>(Theoretical Comparisons between GPT and Bert)</strong></span><br>
                [<a href="https://openreview.net/pdf?id=2rPoTgEmjV" target="_blank">PDF</a>]
                [<a href="https://github.com/PKU-ML/LookAheadLookAround" target="_blank">Code</a>]
                [<a href="javascript:togglebib('zhang2024look')">Bib</a>]<br>
                <pre style="display: none">
                            @inproceedings{zhang2024look,
                            title={Look Ahead or Look Around? A Theoretical Comparison Between Autoregressive and Masked Pretraining},
                            author={Qi Zhang and Tianqi Du and Haotian Huang and Yifei Wang and Yisen Wang},
                            booktitle={ICML},
                            year={2024}
                            }
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="selected 2024 Adv">
              <div class="text" id="li2024pid">
              <ul>
                <li><strong>PID: Prompt-Independent Data Protection Against Latent Diffusion Models</strong><br>
                Ang Li, Yichuan Mo, Mingjie Li, <strong>Yisen Wang#</strong><br>
                <em><strong>ICML 2024</strong></em> <span style="color: red;"><strong>(Unlearning in Diffusion Models)</strong></span> <br>
                [<a href="https://openreview.net/pdf?id=1N7pjXKkx8" target="_blank">PDF</a>]
                [<a href="https://github.com/PKU-ML/Diffusion-PID-Protection" target="_blank">Code</a>]
                [<a href="javascript:togglebib('li2024pid')">Bib</a>]<br>
                <pre style="display: none">
                            @inproceedings{li2024pid,
                            title={{PID}: Prompt-Independent Data Protection Against Latent Diffusion Models},
                            author={Ang Li and Yichuan Mo and Mingjie Li and Yisen Wang},
                            booktitle={ICML},
                            year={2024}
                            }
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="2024 Adv">
              <div class="text" id="mo2024terd">
              <ul>
                <li><strong>TERD: A Unified Framework for Backdoor Defense on Diffusion Model</strong><br>
                Yichuan Mo, Hui Huang, Mingjie Li, Ang Li, <strong>Yisen Wang#</strong><br>
                <em><strong>ICML 2024</strong></em> <strong><font color="#ff0000"></font></strong><br>
                [<a href="https://openreview.net/pdf?id=lpHjmPvxW1" target="_blank">PDF</a>]
                [<a href="https://github.com/PKU-ML/TERD" target="_blank">Code</a>]
                [<a href="javascript:togglebib('mo2024terd')">Bib</a>]<br>
                <pre style="display: none">
                        @inproceedings{mo2024terd,
                        title={{TERD}: A Unified Framework for Safeguarding Diffusion Models Against Backdoors},
                        author={Yichuan Mo and Hui Huang and Mingjie Li and Ang Li and Yisen Wang},
                        booktitle={ICML},
                        year={2024}
                        }
                </pre>
              </li>
              </ul>
              </div>
            </div>




            <div class="selected 2024 SSL">
              <div class="text" id="du2024on">
              <ul>
                <li><strong>On the Role of Discrete Tokenization in Visual Representation Learning</strong><br>
                Tianqi Du, Yifei Wang, <strong>Yisen Wang#</strong><br>
                <em><strong>ICLR 2024</strong></em> <strong><font color="#ff0000">(Spotlight, Top 5%)</font></strong><br>
                [<a href="https://openreview.net/pdf?id=WNLAkjUm19" target="_blank">PDF</a>]
                [<a href="https://github.com/PKU-ML/ClusterMIM" target="_blank">Code</a>]
                [<a href="javascript:togglebib('du2024on')">Bib</a>]<br>
                <pre style="display: none">
                            @inproceedings{du2024on,
                              title={On the Role of Discrete Tokenization in Visual Representation Learning},
                              author={Du, Tianqi and Wang, Yifei and Wang, Yisen},
                              booktitle={ICLR},
                              year={2024}
                            }
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="selected 2024 SSL">
              <div class="text" id="wang2024do">
              <ul>
                <li><strong>Do Generated Data Always Help Contrastive Learning?</strong><br>
                Yifei Wang, Jizhe Zhang, <strong>Yisen Wang#</strong><br>
                <em><strong>ICLR 2024</strong></em> <strong><font color="#ff0000"></font></strong><br>
                [<a href="https://openreview.net/pdf?id=S5EqslEHnz" target="_blank">PDF</a>]
                [<a href="https://github.com/PKU-ML/adainf" target="_blank">Code</a>]
                [<a href="https://mp.weixin.qq.com/s/MSSzIl3KnvRzgWVN0ZyW6A" target="_blank">Featured by Synced</a>]
                [<a href="javascript:togglebib('wang2024do')">Bib</a>]<br>
                <pre style="display: none">
                              @inproceedings{wang2024do,
                              title={Do Generated Data Always Help Contrastive Learning?},
                              author={Yifei Wang and Jizhe Zhang and Yisen Wang},
                              booktitle={ICLR},
                              year={2024}
                              }
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="selected 2024 SSL">
              <div class="text" id="wang2024nonnegative">
              <ul>
                <li><strong>Non-negative Contrastive Learning</strong><br>
                Yifei Wang, Qi Zhang, Yaoyu Guo, <strong>Yisen Wang#</strong><br>
                <em><strong>ICLR 2024</strong></em> <strong><font color="#ff0000"></font></strong><br>
                [<a href="https://openreview.net/pdf?id=lNCnZwcH5Z" target="_blank">PDF</a>]
                [<a href="https://github.com/PKU-ML/non_neg" target="_blank">Code</a>]
                [<a href="javascript:togglebib('wang2024nonnegative')">Bib</a>]<br>
                <pre style="display: none">
                          @inproceedings{wang2024nonnegative,
                          title={Non-negative Contrastive Learning},
                          author={Yifei Wang and Qi Zhang and Yaoyu Guo and Yisen Wang},
                          booktitle={ICLR},
                          year={2024},
                          }
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="selected Preprint">
              <div class="text" id="wei2023jailbreak">
              <ul>
                <li><strong>Jailbreak and Guard Aligned Language Models with Only Few In-Context Demonstrations</strong><br>
                Zeming Wei, Yifei Wang, <strong>Yisen Wang#</strong><br>
                <em><strong>Preprint</strong></em> <strong style="color: red;">(Featured and Scaled up by Claude 3 Group)</strong> <br>
                [<a href="https://arxiv.org/abs/2310.06387" target="_blank">PDF</a>]
                [<a href="" target="_blank">Code</a>]
                [<a href="https://www.anthropic.com/research/many-shot-jailbreaking" target="_blank">Claude 3 Blog</a>]
                [<a href="javascript:togglebib('wei2023jailbreak')">Bib</a>]<br>
                <pre style="display: none">
                      @article{wei2023jailbreak,
                        title={Jailbreak and Guard Aligned Language Models with Only Few In-Context Demonstrations},
                        author={Wei, Zeming and Wang, Yifei and Wang, Yisen},
                        journal={arXiv preprint arXiv:2310.06387},
                        year={2023}
                      }
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="2024 SNN">
              <div class="text" id="yan2024sampling">
              <ul>
                <li><strong>Sampling Complex Topology Structures for Spiking Neural Networks</strong><br>
                Shen Yan, Qingyan Meng, Mingqing Xiao, <strong>Yisen Wang</strong>, Zhouchen Lin<br>
                <em><strong>Neural Networks, 2024</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0893608024000352" target="_blank">PDF</a>]
                [<a href="javascript:togglebib('yan2024sampling')">Bib</a>]<br>
                <pre style="display: none">
                          @article{yan2024sampling,
                              title={Sampling complex topology structures for spiking neural networks},
                              author={Yan, Shen and Meng, Qingyan and Xiao, Mingqing and Wang, Yisen and Lin, Zhouchen},
                              journal={Neural Networks},
                              volume={172},
                              pages={106121},
                              year={2024},
                              publisher={Elsevier}
                            }
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="selected 2023 Adv">
              <div class="text" id="li2023advnotrealfeatures">
              <ul>
                <li><strong>Adversarial Examples Are Not Real Features</strong><br>
                Ang Li, Yifei Wang, Yiwen Guo, <strong>Yisen Wang#</strong><br>
                <em><strong>NeurIPS 2023</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://papers.nips.cc/paper_files/paper/2023/file/378b284f7f03274d1bf5322bb15c5c16-Paper-Conference.pdf" target="_blank">PDF</a>]
                [<a href="https://github.com/PKU-ML/AdvNotRealFeatures" target="_blank">Code</a>]
                [<a href="javascript:togglebib('li2023advnotrealfeatures')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{li2023advnotrealfeatures,
                          title={Adversarial Examples Are Not Real Features},
                          author={Li, Ang and Wang, Yifei and Guo, Yiwen and Wang, Yisen},
                          booktitle={NeurIPS},
                          year={2023}
                      }
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="2023 Adv">
              <div class="text" id="wang2023balance">
              <ul>
                <li><strong>Balance, Imbalance, and Rebalance: Understanding Robust Overfitting from a Minimax Game Perspective</strong><br>
                Yifei Wang, Liangchen Li, Jiansheng Yang, Zhouchen Lin, <strong>Yisen Wang#</strong><br>
                <em><strong>NeurIPS 2023</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://papers.nips.cc/paper_files/paper/2023/file/32f9049217da6e718a426b07242dff73-Paper-Conference.pdf" target="_blank">PDF</a>]
                [<a href="https://github.com/PKU-ML/ReBAT" target="_blank">Code</a>]
                [<a href="javascript:togglebib('wang2023balance')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{wang2023balance,
                        title={Balance, Imbalance, and Rebalance: Understanding Robust Overfitting from a Minimax Game Perspective},
                        author={Wang, Yifei and Li, Liangchen and Yang, Jiansheng and Lin, Zhouchen and Wang, Yisen},
                        booktitle={NeurIPS},
                        year={2023}
                      }
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="selected 2023 SSL">
              <div class="text" id="zhang2023tricontrastive">
              <ul>
                <li><strong>Identifiable Contrastive Learning with Automatic Feature Importance Discovery</strong><br>
                Qi Zhang, Yifei Wang, <strong>Yisen Wang#</strong><br>
                <em><strong>NeurIPS 2023</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://papers.nips.cc/paper_files/paper/2023/file/b6a171867138c80de2a35a6125d6757c-Paper-Conference.pdf" target="_blank">PDF</a>]
                [<a href="https://github.com/PKU-ML/Tri-factor-Contrastive-Learning" target="_blank">Code</a>]
                [<a href="javascript:togglebib('zhang2023tricontrastive')">Bib</a>]<br>
                <pre style="display: none">
                        @inproceedings{zhang2023tricontrastive,
                        title={Identifiable Contrastive Learning with Automatic Feature Importance Discovery},
                        author={Qi Zhang and Yifei Wang and Yisen Wang},
                        booktitle={NeurIPS},
                        year={2023},
                        }
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="selected 2023 SSL">
              <div class="text" id="guo2023architecture">
              <ul>
                <li><strong>Architecture Matters: Uncovering Implicit Mechanisms in Graph Contrastive Learning</strong><br>
                Xiaojun Guo, Yifei Wang, Zeming Wei, <strong>Yisen Wang#</strong><br>
                <em><strong>NeurIPS 2023</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://papers.nips.cc/paper_files/paper/2023/file/5acf5a0ee5c17d372bfe7fdaeffd6e33-Paper-Conference.pdf" target="_blank">PDF</a>]
                [<a href="https://github.com/PKU-ML/ArchitectureMattersGCL" target="_blank">Code</a>]
                [<a href="javascript:togglebib('guo2023architecture')">Bib</a>]<br>
                <pre style="display: none">
                        @inproceedings{guo2023architecture,
                          title={Architecture Matters: Uncovering Implicit Mechanisms in Graph Contrastive Learning},
                          author={Xiaojun Guo and Yifei Wang and Zeming Wei and Yisen Wang},
                          booktitle={NeurIPS},
                          year={2023}
                        }
                </pre>
              </li>
              </ul>
              </div>
            </div>


            <div class="2023 Graph">
              <div class="text" id="ma2023laplacian">
              <ul>
                <li><strong>Laplacian Canonization: A Minimalist Approach to Sign and Basis Invariant Spectral Embedding</strong><br>
                Jiangyan Ma, Yifei Wang, <strong>Yisen Wang#</strong><br>
                <em><strong>NeurIPS 2023</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://papers.nips.cc/paper_files/paper/2023/file/257b3a7438b1f3709e91a86adf2fdc0a-Paper-Conference.pdf" target="_blank">PDF</a>]
                [<a href="https://github.com/PKU-ML/LaplacianCanonization" target="_blank">Code</a>]
                [<a href="javascript:togglebib('ma2023laplacian')">Bib</a>]<br>
                <pre style="display: none">
                        @inproceedings{ma2023laplacian,
                            title={{Laplacian Canonization: A Minimalist Approach to Sign and Basis Invariant Spectral Embedding}},
                            author={Ma, George and Wang, Yifei and Wang, Yisen},
                            booktitle={NeurIPS},
                            year={2023}
                        }
                </pre>
              </li>
              </ul>
              </div>
            </div>



            <div class=" 2023 ">
              <div class="text" id="li2023geq">
              <ul>
                <li><strong>GEQ: Gaussian Kernel Inspired Equilibrium Models</strong><br>
                Mingjie Li, <strong>Yisen Wang</strong>, Zhouchen Lin<br>
                <em><strong>NeurIPS 2023</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://papers.nips.cc/paper_files/paper/2023/file/79cab89b43ac21c6941ad9735df95d30-Paper-Conference.pdf" target="_blank">PDF</a>]
<!--                [<a href="" target="_blank">Code</a>]-->
                [<a href="javascript:togglebib('li2023geq')">Bib</a>]<br>
                <pre style="display: none">
                            @inproceedings{li2023geq,
                              title={GEQ: Gaussian Kernel Inspired Equilibrium Models},
                              author={Li, Mingjie and Wang, Yisen and Lin, Zhouchen},
                              booktitle={NeurIPS},
                              year={2023}
                            }
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="selected 2023 SSL">
              <div class="text" id="zhang2023on">
              <ul>
                <li><strong>On the Generalization of Multimodal Contrastive Learning</strong><br>
                Qi Zhang*, Yifei Wang*, <strong>Yisen Wang#</strong><br>
                <em><strong>ICML 2023</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://proceedings.mlr.press/v202/zhang23an/zhang23an.pdf" target="_blank">PDF</a>]
                [<a href="https://github.com/PKU-ML/CLIP-Help-SimCLR" target="_blank">Code</a>]
                [<a href="javascript:togglebib('zhang2023on')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{zhang2023on,
                      title={On the Generalization of Multi-modal Contrastive Learning},
                      author={Qi Zhang and Yifei Wang and Yisen Wang},
                      booktitle={ICML},
                      year={2023}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="selected 2023 SSL">
              <div class="text" id="cui2023rethinking">
              <ul>
                <li><strong>Rethinking Weak Supervision in Helping Contrastive Learning</strong><br>
                Jingyi Cui*, Weiran Huang*, Yifei Wang*, <strong>Yisen Wang#</strong><br>
                <em><strong>ICML 2023</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://proceedings.mlr.press/v202/cui23a/cui23a.pdf" target="_blank">PDF</a>]
<!--                [<a href="" target="_blank">Code</a>]-->
                [<a href="javascript:togglebib('cui2023rethinking')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{cui2023rethinking,
                        title={Rethinking Weak Supervision in Helping Contrastive Learning},
                        author={Cui, Jingyi and Huang, Weiran and Wang, Yifei and Wang, Yisen},
                        booktitle={ICML},
                        year={2023}}
                </pre>
              </li>
              </ul>
              </div>
            </div>



            <div class="selected 2023 Adv">
              <div class="text" id="wang2023simple">
              <ul>
                <li><strong>Generalist: Decoupling Natural and Robust Generalization</strong><br>
                Hongjun Wang, <strong>Yisen Wang#</strong><br>
                <em><strong>CVPR 2023</strong></em> <strong><font color="#ff0000">(Highlight, Top 2.5%)</font></strong> <br>
                [<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Generalist_Decoupling_Natural_and_Robust_Generalization_CVPR_2023_paper.pdf" target="_blank">PDF</a>]
                [<a href="https://github.com/PKU-ML/Generalist" target="_blank">Code</a>]
                [<a href="javascript:togglebib('wang2023simple')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{wang2023simple,
                        title={Generalist: Decoupling Natural and Robust Generalization},
                        author={Hongjun Wang and Yisen Wang},
                        booktitle={CVPR},
                        year={2023}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="2023 Adv">
              <div class="text" id="wei2023cfa">
              <ul>
                <li><strong>CFA: Class-wise Calibrated Fair Adversarial Training</strong><br>
                Zeming Wei, Yifei Wang, Yiwen Guo, <strong>Yisen Wang#</strong><br>
                <em><strong>CVPR 2023</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Wei_CFA_Class-Wise_Calibrated_Fair_Adversarial_Training_CVPR_2023_paper.pdf" target="_blank">PDF</a>]
                [<a href="https://github.com/PKU-ML/CFA" target="_blank">Code</a>]
                [<a href="javascript:togglebib('wei2023cfa')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{wei2023cfa,
                        title={CFA: Class-wise Calibrated Fair Adversarial Training},
                        author={Wei, Zeming and Wang, Yifei and Guo, Yiwen and Wang, Yisen},
                        booktitle={CVPR},
                        year={2023}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="2023 SNN">
              <div class="text" id="meng2023towards">
              <ul>
                <li><strong>Towards Memory- and Time-Efficient Backpropagation for Training Spiking Neural Networks</strong>  <br>
                Qingyan Meng, Mingqing Xiao, Shen Yan, <strong>Yisen Wang</strong>, Zhouchen Lin, Zhiquan Luo <br>
                <em><strong>ICCV 2023</strong></em> <br>
                [<a href="https://arxiv.org/pdf/2302.14311.pdf" target="_blank">PDF</a>]
                [<a href="javascript:togglebib('meng2023towards')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{meng2022training1,
                        title={Towards Memory- and Time-Efficient Backpropagation for Training Spiking Neural Networks},
                        author={Meng, Qingyan and Xiao, Mingqing and Yan, Shen and Wang, Yisen and Lin, Zhouchen and Luo, Zhi-Quan},
                        booktitle={ICCV},
                        year={2023}}
                </pre>
              </li>
              </ul>
              </div>
            </div>


            <div class="2023 ">
              <div class="text" id="10070588">
              <ul>
                <li><strong>Equilibrium Image Denoising with Implicit Differentiation</strong><br>
                Qi Chen, Yifei Wang, Zhengyang Geng, <strong>Yisen Wang</strong>, Jiansheng Yang, Zhouchen Lin<br>
                <em><strong>IEEE Transaction on Image Processing, 2023</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://ieeexplore.ieee.org/document/10070588" target="_blank">PDF</a>]
                [<a href="javascript:togglebib('10070588')">Bib</a>]<br>
                <pre style="display: none">
                      @ARTICLE{10070588,
                          author={Chen, Qi and Wang, Yifei and Geng, Zhengyang and Wang, Yisen and Yang, Jiansheng and Lin, Zhouchen},
                          journal={IEEE Transactions on Image Processing},
                          title={Equilibrium Image Denoising with Implicit Differentiation},
                          year={2023},
                          volume={},
                          number={},
                          pages={1-1},
                          doi={10.1109/TIP.2023.3255104}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="2023 SNN">
              <div class="text" id="xiao2023spide">
              <ul>
                <li><strong>SPIDE: A Purely Spike-based Method for Training Feedback Spiking Neural Networks</strong><br>
                Mingqing Xiao, Qingyan Meng, Zongpeng Zhang, <strong>Yisen Wang</strong>, Zhouchen Lin<br>
                <em><strong>Neural Networks, 2023</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0893608023000266?via%3Dihub" target="_blank">PDF</a>]
                [<a href="javascript:togglebib('xiao2023spide')">Bib</a>]<br>
                <pre style="display: none">
                          @article{xiao2023spide,
                            title={SPIDE: A purely spike-based method for training feedback spiking neural networks},
                            author={Xiao, Mingqing and Meng, Qingyan and Zhang, Zongpeng and Wang, Yisen and Lin, Zhouchen},
                            journal={Neural Networks},
                            volume={161},
                            pages={9--24},
                            year={2023},
                            publisher={Elsevier}}
                </pre>
              </li>
              </ul>
              </div>
            </div>



            <div class="selected 2023 SSL">
              <div class="text" id="zhuo2023towards">
              <ul>
                <li><strong>Towards a Unified Theoretical Understanding of Non-contrastive Learning via Rank Differential Mechanism</strong><br>
                Zhijian Zhuo*, Yifei Wang*, Jinwen Ma, <strong>Yisen Wang#</strong><br>
                <em><strong>ICLR 2023</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://openreview.net/forum?id=cIbjyd2Vcy" target="_blank">PDF</a>]
                [<a href="https://github.com/PKU-ML/Rank-Differential-Mechanism" target="_blank">Code</a>]
                [<a href="javascript:togglebib('zhuo2023towards')">Bib</a>]<br>
                <pre style="display: none">
                    @inproceedings{zhuo2023towards,
                          title={Towards a Unified Theoretical Understanding of Non-contrastive Learning via Rank Differential Mechanism},
                          author={Zhuo, Zhijian and Wang, Yifei and Ma, Jinwen and Wang, Yisen},
                          booktitle={ICLR},
                          year={2023}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="selected 2023 SSL">
              <div class="text" id="guo2023contranorm">
              <ul>
                <li><strong>ContraNorm: A Contrastive Learning Perspective on Oversmoothing and Beyond</strong><br>
                Xiaojun Guo*, Yifei Wang*, Tianqi Du*, <strong>Yisen Wang#</strong><br>
                <em><strong>ICLR 2023</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://openreview.net/forum?id=SM7XkJouWHm" target="_blank">PDF</a>]
                [<a href="https://github.com/PKU-ML/ContraNorm" target="_blank">Code</a>]
                [<a href="javascript:togglebib('guo2023contranorm')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{guo2023contranorm,
                        title={ContraNorm: A Contrastive Learning Perspective on Oversmoothing and Beyond},
                        author={Guo, Xiaojun and Wang, Yifei and Du, Tianqi and Wang, Yisen},
                        booktitle={ICLR},
                        year={2023}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="selected 2023 SSL">
              <div class="text" id="wang2023message">
              <ul>
                <li><strong>A Message Passing Perspective on Learning Dynamics of Contrastive Learning</strong><br>
                Yifei Wang*, Qi Zhang*, Tianqi Du, Jiansheng Yang, Zhouchen Lin, <strong>Yisen Wang#</strong><br>
                <em><strong>ICLR 2023</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://openreview.net/forum?id=VBTJqqWjxMv" target="_blank">PDF</a>]
                [<a href="https://github.com/PKU-ML/Message-Passing-Contrastive-Learning" target="_blank">Code</a>]
                [<a href="javascript:togglebib('wang2023message')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{wang2023message,
                        title={A Message Passing Perspective on Learning Dynamics of Contrastive Learning},
                        author={Wang, Yifei and Zhang, Qi and Du, Tianqi and Yang, Jiansheng and Lin, Zhouchen and Wang, Yisen},
                        booktitle={ICLR},
                        year={2023}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="selected 2023 SSL Adv">
              <div class="text" id="luo2023rethinking">
              <ul>
                <li><strong>Rethinking the Effect of Data Augmentation in Adversarial Contrastive Learning</strong><br>
                Rundong Luo*, Yifei Wang*, <strong>Yisen Wang#</strong><br>
                <em><strong>ICLR 2023</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://openreview.net/forum?id=0qmwFNJyxCL" target="_blank">PDF</a>]
                [<a href="https://github.com/PKU-ML/DynACL" target="_blank">Code</a>]
                [<a href="javascript:togglebib('luo2023rethinking')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{luo2023rethinking,
                              title = {Rethinking the Effect of Data Augmentation in Adversarial Contrastive Learning},
                              author = {Luo, Rundong and Wang, Yifei and Wang, Yisen},
                              booktitle={ICLR},
                              year = {2023}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="2023 SSL">
              <div class="text" id="zhao2023arcl">
              <ul>
                <li><strong>ArCL: Enhancing Contrastive Learning with Augmentation-Robust Representations</strong><br>
                Xuyang Zhao*, Tianqi Du*, <strong>Yisen Wang</strong>, Jun Yao, Weiran Huang<br>
                <em><strong>ICLR 2023</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://openreview.net/forum?id=n0Pb9T5kmb" target="_blank">PDF</a>]
                [<a href="" target="_blank">Code</a>]
                [<a href="javascript:togglebib('zhao2023arcl')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{zhao2023arcl,
                        title={ArCL: Enhancing Contrastive Learning with Augmentation-Robust Representations},
                        author={Zhao, Xuyang and Du, Tianqi and Wang, Yisen and Yao, Jun and Huang, Weiran},
                        booktitle={ICLR},
                        year={2023}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="2023 Graph">
              <div class="text" id="li2023unbiased">
              <ul>
                <li><strong>Unbiased Stochastic Proximal Solver for Graph Neural Networks with Equilibrium States</strong><br>
                Mingjie Li, Yifei Wang, <strong>Yisen Wang</strong>, Zhouchen Lin<br>
                <em><strong>ICLR 2023</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://openreview.net/forum?id=j3cUWIMsFBN" target="_blank">PDF</a>]
                [<a href="" target="_blank">Code</a>]
                [<a href="javascript:togglebib('li2023unbiased')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{li2023unbiased,
                        title={Unbiased Stochastic Proximal Solver for Graph Neural Networks with Equilibrium States},
                        author={Li, Mingjie and Wang, Yifei and Wang, Yisen and Lin, Zhouchen},
                        booktitle={ICLR}
                        year={2023}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="2023 SSL">
              <div class="text" id="xin2023domainwise">
              <ul>
                <li><strong>On the Connection between Invariant Learning and Adversarial Training for Out-of-Distribution Generalization</strong><br>
                Shiji Xin, Yifei Wang, Jingtong Su, <strong>Yisen Wang#</strong><br>
                <em><strong>AAAI 2023</strong></em> <strong><font color="#ff0000">(Oral)</font></strong> <br>
                [<a href="https://arxiv.org/pdf/2212.09082.pdf" target="_blank">PDF</a>]
                [<a href="javascript:togglebib('xin2023domainwise')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{xin2022connection,
                          title={On the Connection between Invariant Learning and Adversarial Training for Out-of-Distribution Generalization},
                          author={Xin, Shiji and Wang, Yifei and Su, Jingtong and Wang, Yisen},
                          journal={AAAI},
                          year={2023}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="selected 2022 SSL">
              <div class="text" id="zhang2022mask">
              <ul>
                <li><strong>How Mask Matters: Towards Theoretical Understandings of Masked Autoencoders</strong><br>
                Qi Zhang*, Yifei Wang*, <strong>Yisen Wang#</strong><br>
                <em><strong>NeurIPS 2022</strong></em> <strong><font color="#ff0000">(Spotlight, Top 5%)</font></strong><br>
                [<a href="https://papers.nips.cc/paper_files/paper/2022/file/adb2075b6dd31cb18dfa727240d2887e-Paper-Conference.pdf" target="_blank">PDF</a>]
                [<a href="https://github.com/PKU-ML/U-MAE" target="_blank">Code</a>]
                [<a href="javascript:togglebib('zhang2022mask')">Bib</a>]<br>
                <pre style="display: none">
                    @inproceedings{zhang2022mask,
                      title={How Mask Matters: Towards Theoretical Understandings of Masked Autoencoders},
                      author={Zhang, Qi and Wang, Yifei and Wang, Yisen},
                      booktitle={NeurIPS},
                      year={2022}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

<!--            <div class="Adv">-->
<!--              <div class="text">-->
<!--              <ul>-->
<!--                <li><strong>VALSE Tutorial: Adversarial Attack and Defense</strong> (in Chinese)<br>-->
<!--                <strong>Yisen Wang</strong> <br>-->
<!--                [<a href="https://www.bilibili.com/video/BV1Pf4y1c7dg/?spm_id_from=333.999.0.0" target="_blank">Video</a>]-->
<!--                [<a href="https://mp.weixin.qq.com/s/-lzPJFRmRhgqfJp4ckqMCw" target="_blank">Note</a>]-->
<!--              </li>-->
<!--              </ul>-->
<!--              </div>-->
<!--            </div>-->

            <div class="selected 2022 Adv">
              <div class="text" id="mo2022adversarial">
              <ul>
                <li><strong>When Adversarial Training Meets Vision Transformers: Recipes from Training to Architecture</strong><br>
                Yichuan Mo, Dongxian Wu, Yifei Wang, Yiwen Guo, <strong>Yisen Wang#</strong> <br>
                <em><strong>NeurIPS 2022</strong></em> <strong><font color="#ff0000">(Spotlight, Top 5%)</font></strong><br>
                [<a href="https://papers.nips.cc/paper_files/paper/2022/file/760b5def8dcb1156aac454e9c0f5f406-Paper-Conference.pdf" target="_blank">PDF</a>]
                [<a href="https://github.com/PKU-ML/When-Adversarial-Training-Meets-Vision-Transformers" target="_blank">Code</a>]
                [<a href="javascript:togglebib('mo2022adversarial')">Bib</a>]<br>
                <pre style="display: none">
                    @inproceedings{mo2022adversarial,
                      title={When Adversarial Training Meets Vision Transformers: Recipes from Training to Architecture},
                      author={Mo, Yichuan and Wu, Dongxian and Wang, Yifei and Guo, Yiwen and Wang, Yisen},
                      booktitle={NeurIPS},
                      year={2022}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="2022 SSL">
              <div class="text" id="wang2022improving">
              <ul>
                <li><strong>Improving Out-of-Distribution Generalization by Adversarial Training with Structured Priors</strong><br>
                Qixun Wang*, Yifei Wang*, Hong Zhu, <strong>Yisen Wang#</strong> <br>
                <em><strong>NeurIPS 2022</strong></em> <strong><font color="#ff0000">(Spotlight, Top 5%)</font></strong><br>
                [<a href="https://papers.nips.cc/paper_files/paper/2022/file/adc98a266f45005c403b8311ca7e8bd7-Paper-Conference.pdf" target="_blank">PDF</a>]
                [<a href="https://github.com/PKU-ML/AT-for-OOD" target="_blank">Code</a>]
                [<a href="javascript:togglebib('wang2022improving')">Bib</a>]<br>
                <pre style="display: none">
                    @inproceedings{wang2022improving,
                      title={Improving Out-of-Distribution Generalization by Adversarial Training with Structured Priors},
                      author={Wang, Qixun and Wang, Yifei and Zhu, Hong and Wang, Yisen},
                      booktitle={NeurIPS},
                      year={2022}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

<!--            <div class="2022 SSL">-->
<!--              <div class="text" id="cui2022aggnce">-->
<!--              <ul>-->
<!--                <li><strong>AggNCE: Asymptotically Identifiable Contrastive Learning</strong><br>-->
<!--                Jingyi Cui*, Weiran Huang*, Yifei Wang, <strong>Yisen Wang#</strong> <br>-->
<!--                <em><strong>NeurIPS 2022 Workshop on Self-Supervised Learning Theory and Practice</strong></em> <strong><font color="#ff0000">(Oral)</font></strong><br>-->
<!--                [<a href="https://sslneurips22.github.io/paper_pdfs/paper_68.pdf" target="_blank">PDF</a>]-->
<!--                [<a href="javascript:togglebib('cui2022aggnce')">Bib</a>]<br>-->
<!--                <pre style="display: none">-->
<!--                    @inproceedings{cui2022aggnce,-->
<!--                      title={AggNCE: Asymptotically Identifiable Contrastive Learning},-->
<!--                      author={Cui, Jingyi and Huang, Weiran and Wang, Yifei and Wang, Yisen},-->
<!--                      booktitle={NeurIPS Workshop},-->
<!--                      year={2022}}-->
<!--                </pre>-->
<!--              </li>-->
<!--              </ul>-->
<!--              </div>-->
<!--            </div>-->

<!--            <div class="2022 SSL">-->
<!--              <div class="text" id="du2022variational">-->
<!--              <ul>-->
<!--                <li><strong>Variational Energy-Based Models: A Probabilistic Framework for Contrastive Self-Supervised Learning</strong><br>-->
<!--                Tianqi Du*, Yifei Wang*, Weiran Huang, <strong>Yisen Wang#</strong> <br>-->
<!--                <em><strong>NeurIPS 2022 Workshop on Self-Supervised Learning Theory and Practice</strong></em> <strong><font color="#ff0000"></font></strong><br>-->
<!--                [<a href="https://sslneurips22.github.io/paper_pdfs/paper_64.pdf" target="_blank">PDF</a>]-->
<!--                [<a href="javascript:togglebib('du2022variational')">Bib</a>]<br>-->
<!--                <pre style="display: none">-->
<!--                      @inproceedings{du2022variational,-->
<!--                        title={Variational Energy-Based Models: A Probabilistic Framework for Contrastive Self-Supervised Learning},-->
<!--                        author={Du, Tianqi and Wang, Yifei and Huang, Weiran and Wang, Yisen},-->
<!--                        booktitle={NeurIPS Workshop},-->
<!--                        year={2022}}-->
<!--                </pre>-->
<!--              </li>-->
<!--              </ul>-->
<!--              </div>-->
<!--            </div>-->


            <div class="2022 Adv">
              <div class="text" id="kou2022certified">
              <ul>
                <li><strong>Certified Adversarial Robustness Under the Bounded Support Set</strong> <br>
                Yiwen Kou, Qinyuan Zheng, <strong>Yisen Wang#</strong> <br>
                <em><strong>ICML 2022</strong></em> <br>
                [<a href="https://proceedings.mlr.press/v162/kou22a/kou22a.pdf" target="_blank">PDF</a>]
                [<a href="javascript:togglebib('kou2022certified')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{kou2022certified,
                        title={Certified Adversarial Robustness Under the Bounded Support Set},
                        author={Kou, Yiwen and Zheng, Qinyuan and Wang, Yisen},
                        booktitle={ICML},
                        year={2022}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="2022 Adv">
              <div class="text" id="li2022cerdeq">
              <ul>
                <li><strong>CerDEQ: Certifiable Deep Equilibrium Model</strong> <br>
                Mingjie Li, <strong>Yisen Wang</strong>, Zhouchen Lin <br>
                <em><strong>ICML 2022</strong></em> <br>
                [<a href="https://proceedings.mlr.press/v162/li22t/li22t.pdf" target="_blank">PDF</a>]
                [<a href="javascript:togglebib('li2022cerdeq')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{li2022cerdeq,
                        title={CerDEQ: Certifiable Deep Equilibrium Model},
                        author={Li, Mingjie and Wang, Yisen and Lin, Zhouchen},
                        booktitle={ICML},
                        year={2022}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="2022 Graph">
              <div class="text" id="chen2022optimization">
              <ul>
                <li><strong>Optimization-Induced Graph Implicit Nonlinear Diffusion</strong> <br>
                Qi Chen, Yifei Wang, <strong>Yisen Wang</strong>, Jiansheng Yang, Zhouchen Lin <br>
                <em><strong>ICML 2022</strong></em> <br>
                [<a href="https://proceedings.mlr.press/v162/chen22z/chen22z.pdf" target="_blank">PDF</a>]
                [<a href="https://github.com/7qchen/GIND" target="_blank">Code</a>]
                [<a href="javascript:togglebib('chen2022optimization')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{chen2022optimization,
                        title={Optimization-Induced Graph Implicit Nonlinear Diffusion},
                        author={Chen, Qi and Wang, Yifei and Wang, Yisen and Yang, Jiansheng and Lin, Zhouchen},
                        booktitle={ICML},
                        year={2022}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="2022 Graph">
              <div class="text" id="li2022g">
              <ul>
                <li><strong>G2CN: Graph Gaussian Convolution Networks with Concentrated Graph Filters</strong><br>
                Mingjie Li, Xiaojun Guo, Yifei Wang, <strong>Yisen Wang</strong>, Zhouchen Lin <br>
                <em><strong>ICML 2022</strong></em> <br>
                [<a href="https://proceedings.mlr.press/v162/li22h/li22h.pdf" target="_blank">PDF</a>]
                [<a href="https://github.com/homles11/G2CN" target="_blank">Code</a>]
                [<a href="javascript:togglebib('li2022g')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{li2022g,
                        title={G $\^{} 2$ CN: Graph Gaussian Convolution Networks with Concentrated Graph Filters},
                        author={Li, Mingjie and Guo, Xiaojun and Wang, Yifei and Wang, Yisen and Lin, Zhouchen},
                        booktitle={ICML},
                        year={2022}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="2022 Adv">
              <div class="text" id="wang2022self">
              <ul>
                <li><strong>Self-ensemble Adversarial Training for Improved Robustness</strong><br>
                Hongjun Wang, <strong>Yisen Wang#</strong> <br>
                <em><strong>ICLR 2022</strong></em> <br>
                [<a href="https://openreview.net/pdf?id=oU3aTsmeRQV" target="_blank">PDF</a>]
                [<a href="https://github.com/whj363636/Self-Ensemble-Adversarial-Training" target="_blank">Code</a>]
                [<a href="javascript:togglebib('wang2022self')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{wang2022self,
                        title={Self-Ensemble Adversarial Training for Improved Robustness},
                        author={Wang, Hongjun and Wang, Yisen},
                        booktitle={ICLR},
                        year={2022}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="selected 2022 Adv">
              <div class="text" id="wang2022unified">
              <ul>
                <li><strong>A Unified Contrastive Energy-based Model for Understanding the Generative Ability of Adversarial Training</strong><br>
                Yifei Wang, <strong>Yisen Wang#</strong>, Jiansheng Yang, Zhouchen Lin <br>
                <em><strong>ICLR 2022</strong></em> <strong><font color="#ff0000">(Silver Best Paper Award at ICML 2021 AdvML Workshop)</font></strong> <br>
                [<a href="https://openreview.net/pdf?id=XhF2VOMRHS" target="_blank">PDF</a>]
                [<a href="javascript:togglebib('wang2022unified')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{wang2022unified,
                        title={A Unified Contrastive Energy-based Model for Understanding the Generative Ability of Adversarial Training},
                        author={Wang, Yifei and Wang, Yisen and Yang, Jiansheng and Lin, Zhouchen},
                        booktitle={ICLR},
                        year={2022}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="selected 2022 SSL">
              <div class="text" id="wang2022chaos">
              <ul>
                <li><strong>Chaos is a Ladder: A New Theoretical Understanding of Contrastive Learning via Augmentation Overlap</strong>  <br>
                Yifei Wang*, Qi Zhang*, <strong>Yisen Wang#</strong>, Jiansheng Yang, Zhouchen Lin <br>
                <em><strong>ICLR 2022</strong></em> <br>
                [<a href="https://openreview.net/pdf?id=ECvgmYVyeUz" target="_blank">PDF</a>]
                [<a href="https://github.com/zhangq327/ARC" target="_blank">Code</a>]
                [<a href="javascript:togglebib('wang2022chaos')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{wang2022chaos,
                        title={Chaos is a ladder: A new theoretical understanding of contrastive learning via augmentation overlap},
                        author={Wang, Yifei and Zhang, Qi and Wang, Yisen and Yang, Jiansheng and Lin, Zhouchen},
                        booktitle={ICLR},
                        year={2022}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="2022">
              <div class="text" id="li2022optimization">
              <ul>
                <li><strong>Optimization inspired Multi-Branch Equilibrium Models</strong> <br>
                Mingjie Li, <strong>Yisen Wang</strong>, Xingyu Xie, Zhouchen Lin <br>
                <em><strong>ICLR 2022</strong></em> <br>
                [<a href="https://openreview.net/pdf?id=nbC8iTTXIrk" target="_blank">PDF</a>]
                [<a href="javascript:togglebib('li2022optimization')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{li2022optimization,
                        title={Optimization inspired Multi-Branch Equilibrium Models},
                        author={Li, Mingjie and Wang, Yisen and Xie, Xingyu and Lin, Zhouchen},
                        booktitle={ICLR},
                        year={2022}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="2022 Adv">
              <div class="text" id="bai2023query">
              <ul>
                <li><strong>Query Efficient Black-box Adversarial Attack on Deep Neural Networks</strong> <br>
                Yang Bai*, <strong>Yisen Wang*</strong>, Yuyuan Zeng, Yong Jiang, Shu-Tao Xia<br>
                <em><strong>Pattern Recognition, 2022</strong></em> <br>
                [<a href="https://www.sciencedirect.com/science/article/pii/S0031320322005179" target="_blank">PDF</a>]
                [<a href="javascript:togglebib('bai2023query')">Bib</a>]<br>
                <pre style="display: none">
                      @article{bai2023query,
                        title={Query efficient black-box adversarial attack on deep neural networks},
                        author={Bai, Yang and Wang, Yisen and Zeng, Yuyuan and Jiang, Yong and Xia, Shu-Tao},
                        journal={Pattern Recognition},
                        volume={133},
                        pages={109037},
                        year={2023},
                        publisher={Elsevier}}
                </pre>
              </li>
              </ul>
              </div>
            </div>



            <div class="2022 SNN">
              <div class="text" id="meng2022training1">
              <ul>
                <li><strong>Training High-Performance Low-Latency Spiking Neural Networks by Differentiation on Spike Representation</strong>  <br>
                Qingyan Meng, Mingqing Xiao, Shen Yan, <strong>Yisen Wang</strong>, Zhouchen Lin, Zhiquan Luo <br>
                <em><strong>CVPR 2022</strong></em> <br>
                [<a href="https://arxiv.org/pdf/2205.00459.pdf" target="_blank">PDF</a>]
                [<a href="https://github.com/qymeng94/DSR" target="_blank">Code</a>]
                [<a href="javascript:togglebib('meng2022training1')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{meng2022training1,
                        title={Training High-Performance Low-Latency Spiking Neural Networks by Differentiation on Spike Representation},
                        author={Meng, Qingyan and Xiao, Mingqing and Yan, Shen and Wang, Yisen and Lin, Zhouchen and Luo, Zhi-Quan},
                        booktitle={CVPR},
                        year={2022}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="2022 SNN">
              <div class="text" id="meng2022training2">
              <ul>
                <li><strong>Training Much Deeper Spiking Neural Networks with A Small Number of Time-Steps</strong>  <br>
                Qingyan Meng, Shen Yan, Mingqing Xiao, <strong>Yisen Wang</strong>, Zhouchen Lin, Zhiquan Luo <br>
                <em><strong>Neural Networks, 2022</strong></em> <br>
                [<a href="https://www.sciencedirect.com/science/article/pii/S0893608022002064" target="_blank">PDF</a>]
                [<a href="javascript:togglebib('meng2022training2')">Bib</a>]<br>
                <pre style="display: none">
                      @article{meng2022training2,
                        title={Training much deeper spiking neural networks with a small number of time-steps},
                        author={Meng, Qingyan and Yan, Shen and Xiao, Mingqing and Wang, Yisen and Lin, Zhouchen and Luo, Zhi-Quan},
                        journal={Neural Networks},
                        volume={153},
                        pages={254--268},
                        year={2022},
                        publisher={Elsevier}}
                </pre>
              </li>
              </ul>
              </div>
            </div>



            <div class="2021 Adv">
              <div class="text" id="bai2021clustering">
              <ul>
                <li><strong>Clustering Effect of (Linearized) Adversarial Robust Models</strong>  <br>
                Yang Bai*, Xin Yan*, Yong Jiang, Shu-Tao Xia#, <strong>Yisen Wang#</strong> <br>
                <em><strong>NeurIPS 2021</strong></em> <strong><font color="#ff0000">(Spotlight, Top 3%)</font></strong> <br>
                [<a href="https://papers.nips.cc/paper/2021/file/f770b62bc8f42a0b66751fe636fc6eb0-Paper.pdf" target="_blank">PDF</a>]
                [<a href="https://github.com/bymavis/Adv_Weight_NeurIPS2021/" target="_blank">Code</a>]
                [<a href="javascript:togglebib('bai2021clustering')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{bai2021clustering,
                        title={Clustering Effect of (Linearized) Adversarial Robust Models},
                        author={Bai, Yang and Yan, Xin and Jiang, Yong and Xia, Shu-Tao and Wang, Yisen},
                        booktitle={NeurIPS},
                        year={2021}}
                </pre>
              </li>
              </ul>
              </div>
            </div>


            <div class="selected 2021 Adv">
              <div class="text" id="wu2021adversarial">
              <ul>
                <li><strong>Adversarial Neuron Pruning Purifies Backdoored Deep Models</strong>  <br>
                Dongxian Wu, <strong>Yisen Wang#</strong> <br>
                <em><strong>NeurIPS 2021</strong></em> <strong><font color="#ff0000">(SOTA Backdoor Defense at BackdoorBench)</font></strong> <br>
                [<a href="https://papers.nips.cc/paper/2021/file/8cbe9ce23f42628c98f80fa0fac8b19a-Paper.pdf" target="_blank">PDF</a>]
                [<a href="https://github.com/csdongxian/ANP_backdoor" target="_blank">Code</a>]
                [<a href="https://backdoorbench.github.io/index.html" target="_blank">BackdoorBench</a>]
                [<a href="javascript:togglebib('wu2021adversarial')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{wu2021adversarial,
                        title={Adversarial neuron pruning purifies backdoored deep models},
                        author={Wu, Dongxian and Wang, Yisen},
                        booktitle={NeurIPS},
                        year={2021}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="2021 SSL">
              <div class="text" id="wang2021residual">
              <ul>
                <li><strong>Residual Relaxation for Multi-view Representation Learning</strong>  <br>
                Yifei Wang, Zhengyang Geng, Feng Jiang, Chuming Li, <strong>Yisen Wang#</strong>, Jiansheng Yang, Zhouchen Lin <br>
                <em><strong>NeurIPS 2021</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://papers.nips.cc/paper/2021/file/6516c28727509c3db6280ae16254e916-Paper.pdf" target="_blank">PDF</a>]
                [<a href="javascript:togglebib('wang2021residual')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{wang2021residual,
                        title={Residual relaxation for multi-view representation learning},
                        author={Wang, Yifei and Geng, Zhengyang and Jiang, Feng and Li, Chuming and Wang, Yisen and Yang, Jiansheng and Lin, Zhouchen},
                        booktitle={NeurIPS},
                        year={2021}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="2021 Graph">
              <div class="text" id="wang2021dissecting">
              <ul>
                <li><strong>Dissecting the Diffusion Process in Linear Graph Convolutional Networks</strong>  <br>
                Yifei Wang, <strong>Yisen Wang#</strong>, Jiansheng Yang, Zhouchen Lin <br>
                <em><strong>NeurIPS 2021</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://papers.nips.cc/paper/2021/file/2d95666e2649fcfc6e3af75e09f5adb9-Paper.pdf" target="_blank">PDF</a>]
                [<a href="https://github.com/yifeiwang77/DGC" target="_blank">Code</a>]
                [<a href="javascript:togglebib('wang2021dissecting')">Bib</a>]<br>
                <pre style="display: none">
                    @inproceedings{wang2021dissecting,
                      title={Dissecting the diffusion process in linear graph convolutional networks},
                      author={Wang, Yifei and Wang, Yisen and Yang, Jiansheng and Lin, Zhouchen},
                      booktitle={NeurIPS},
                      year={2021}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="2021 Adv">
              <div class="text" id="niu2021morie">
              <ul>
                <li><strong>Moire Attack (MA): A New Potential Risk of Screen Photos</strong>  <br>
                Dantong Niu, Ruohao Guo, <strong>Yisen Wang#</strong> <br>
                <em><strong>NeurIPS 2021</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://papers.nips.cc/paper/2021/file/db9eeb7e678863649bce209842e0d164-Paper.pdf" target="_blank">PDF</a>]
                [<a href="https://github.com/Dantong88/Moire_Attack" target="_blank">Code</a>]
                [<a href="javascript:togglebib('niu2021morie')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{niu2021morie,
                        title={Mori{\'e} Attack (MA): A New Potential Risk of Screen Photos},
                        author={Niu, Dantong and Guo, Ruohao and Wang, Yisen},
                        booktitle={NeurIPS},
                        year={2021}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="2021 Adv">
              <div class="text" id="ren2021unified">
              <ul>
                <li><strong>A Unified Game-Theoretic Interpretation of Adversarial Robustness</strong>  <br>
                Jie Ren*, Die Zhang*, <strong>Yisen Wang*</strong>, Lu Chen, Zhanpeng Zhou, Yiting Chen, Xu Cheng, Xin Wang, Meng Zhou, Jie Shi, Quanshi Zhang <br>
                <em><strong>NeurIPS 2021</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://papers.nips.cc/paper/2021/file/1f4fe6a4411edc2ff625888b4093e917-Paper.pdf" target="_blank">PDF</a>]
                [<a href="https://github.com/Jie-Ren/A-Unified-Game-Theoretic-Interpretation-of-Adversarial-Robustness" target="_blank">Code</a>]
                [<a href="https://zhuanlan.zhihu.com/p/361686461" target="_blank">Zhihu</a>]
                [<a href="javascript:togglebib('ren2021unified')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{ren2021unified,
                        title={A unified game-theoretic interpretation of adversarial robustness},
                        author={Ren, Jie and Zhang, Die and Wang, Yisen and Chen, Lu and Zhou, Zhanpeng and Chen, Yiting and Cheng, Xu and Wang, Xin and Zhou, Meng and Shi, Jie and others},
                        booktitle={NeurIPS},
                        year={2021}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="2021 Adv">
              <div class="text" id="huang2021exploring">
              <ul>
                <li><strong>Exploring Architectural Ingredients of Adversarially Robust Deep Neural Networks</strong>  <br>
                Hanxun Huang, <strong>Yisen Wang</strong>, Sarah Monazam Erfani, Quanquan Gu, James Bailey, Xingjun Ma <br>
                <em><strong>NeurIPS 2021</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://papers.nips.cc/paper/2021/file/2bd7f907b7f5b6bbd91822c0c7b835f6-Paper.pdf" target="_blank">PDF</a>]
                [<a href="https://github.com/HanxunH/RobustWRN" target="_blank">Code</a>]
                [<a href="javascript:togglebib('huang2021exploring')">Bib</a>]<br>
                <pre style="display: none">
                    @inproceedings{huang2021exploring,
                      title={Exploring Architectural Ingredients of Adversarially Robust Deep Neural Networks},
                      author={Huang, Hanxun and Wang, Yisen and Erfani, Sarah Monazam and Gu, Quanquan and Bailey, James and Ma, Xingjun},
                      booktitle={NeurIPS},
                      year={2021}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="2021 Adv">
              <div class="text" id="ma2021finding">
              <ul>
                <li><strong>Finding Optimal Tangent Points for Reducing Distortions of Hard-label Attacks</strong>  <br>
                Chen Ma, Xiangyu Guo, Li Chen, Jun-Hai Yong, <strong>Yisen Wang</strong> <br>
                <em><strong>NeurIPS 2021</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://papers.nips.cc/paper/2021/file/a113c1ecd3cace2237256f4c712f61b5-Paper.pdf" target="_blank">PDF</a>]
                [<a href="https://github.com/machanic/TangentAttack" target="_blank">Code</a>]
                [<a href="javascript:togglebib('ma2021finding')">Bib</a>]<br>
                <pre style="display: none">
                    @inproceedings{ma2021finding,
                      title={Finding Optimal Tangent Points for Reducing Distortions of Hard-label Attacks},
                      author={Ma, Chen and Guo, Xiangyu and Chen, Li and Yong, Jun-Hai and Wang, Yisen},
                      booktitle={NeurIPS},
                      year={2021}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="2021">
              <div class="text" id="geng2021training">
              <ul>
                <li><strong>On Training Implicit Models</strong>  <br>
                Zhengyang Geng, Xin-Yu Zhang, Shaojie Bai, <strong>Yisen Wang</strong>, Zhouchen Lin <br>
                <em><strong>NeurIPS 2021</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://papers.nips.cc/paper/2021/file/cb8da6767461f2812ae4290eac7cbc42-Paper.pdf" target="_blank">PDF</a>]
                [<a href="https://github.com/Gsunshine/phantom_grad" target="_blank">Code</a>]
                [<a href="javascript:togglebib('geng2021training')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{geng2021training,
                        title={On training implicit models},
                        author={Geng, Zhengyang and Zhang, Xin-Yu and Bai, Shaojie and Wang, Yisen and Lin, Zhouchen},
                        booktitle={NeurIPS},
                        year={2021}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="2021">
              <div class="text" id="he2021gauge">
              <ul>
                <li><strong>Gauge Equivariant Transformer</strong>  <br>
                Lingshen He, Yiming Dong, <strong>Yisen Wang</strong>, Dacheng Tao, Zhouchen Lin <br>
                <em><strong>NeurIPS 2021</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://proceedings.neurips.cc/paper/2021/file/e57c6b956a6521b28495f2886ca0977a-Paper.pdf" target="_blank">PDF</a>]
                [<a href="javascript:togglebib('he2021gauge')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{he2021gauge,
                        title={Gauge equivariant transformer},
                        author={He, Lingshen and Dong, Yiming and Wang, Yisen and Tao, Dacheng and Lin, Zhouchen},
                        booktitle={NeurIPS},
                        year={2021}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="2021 SNN">
              <div class="text" id="xiao2021training">
              <ul>
                <li><strong>Training Feedback Spiking Neural Networks by Implicit Differentiation on the Equilibrium State</strong>  <br>
                Mingqing Xiao, Qingyan Meng, Zongpeng Zhang, <strong>Yisen Wang</strong>, Zhouchen Lin <br>
                <em><strong>NeurIPS 2021</strong></em> <strong><font color="#ff0000">(Spotlight, Top 3%)</font></strong> <br>
                [<a href="https://papers.nips.cc/paper/2021/file/79a49b3e3762632813f9e35f4ba53d6c-Paper.pdf" target="_blank">PDF</a>]
                [<a href="https://github.com/pkuxmq/IDE-FSNN" target="_blank">Code</a>]
                [<a href="javascript:togglebib('xiao2021training')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{xiao2021training,
                        title={Training feedback spiking neural networks by implicit differentiation on the equilibrium state},
                        author={Xiao, Mingqing and Meng, Qingyan and Zhang, Zongpeng and Wang, Yisen and Lin, Zhouchen},
                        booktitle={NeurIPS},
                        year={2021}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="selected 2021 Adv">
              <div class="text" id="wang2021reparameterized">
              <ul>
                <li><strong>Reparameterized Sampling for Generative Adversarial Networks</strong>  <br>
                Yifei Wang, <strong>Yisen Wang#</strong>, Jiansheng Yang, Zhouchen Lin <br>
                <em><strong>ECML-PKDD 2021</strong></em> <strong><font color="#ff0000">(Best (Student) Machine Learning Paper Award)</font></strong> <br>
                [<a href="https://arxiv.org/pdf/2107.00352.pdf" target="_blank">PDF</a>]
                [<a href="https://github.com/yifeiwang77/repgan" target="_blank">Code</a>]
                [<a href="https://2021.ecmlpkdd.org/?page_id=2148" target="_blank">Award</a>]
                [<a href="javascript:togglebib('wang2021reparameterized')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{wang2021reparameterized,
                        title={Reparameterized Sampling for Generative Adversarial Networks},
                        author={Wang, Yifei and Wang, Yisen and Yang, Jiansheng and Lin, Zhouchen},
                        booktitle={ECML-PKDD},
                        year={2021}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

<!--            <div class="2021 Adv">-->
<!--              <div class="text" id="wang2021demystifying">-->
<!--              <ul>-->
<!--                <li><strong>Demystifying Adversarial Training via A Unified Probabilistic Framework</strong>  <br>-->
<!--                Yifei Wang, <strong>Yisen Wang#</strong>, Jiansheng Yang, Zhouchen Lin <br>-->
<!--                <em><strong>ICML 2021 Workshop on Adversarial Machine Learning</strong></em> <strong><font color="#ff0000">(Silver Best Paper Award)</font></strong> <br>-->
<!--                [<a href="https://openreview.net/pdf?id=U0TCTe68s41" target="_blank">PDF</a>]-->
<!--                [<a href="https://advml-workshop.github.io/icml2021/" target="_blank">Award</a>]-->
<!--                [<a href="javascript:togglebib('wang2021demystifying')">Bib</a>]<br>-->
<!--                <pre style="display: none">-->
<!--                      @inproceedings{wang2021demystifying,-->
<!--                        title={Demystifying adversarial training via a unified probabilistic framework},-->
<!--                        author={Wang, Yifei and Wang, Yisen and Yang, Jiansheng and Lin, Zhouchen},-->
<!--                        booktitle={ICML 2021 Workshop on Adversarial Machine Learning},-->
<!--                        year={2021}}-->
<!--                </pre>-->
<!--              </li>-->
<!--              </ul>-->
<!--              </div>-->
<!--            </div>-->

            <div class="2021 SSL">
              <div class="text" id="zhang2021can">
              <ul>
                <li><strong>Can Subnetwork Structure be the Key to Out-of-Distribution Generalization?</strong>  <br>
                Dinghuai Zhang, Kartik Ahuja, Yilun Xu, <strong>Yisen Wang</strong>, Aaron Courville<br>
                <em><strong>ICML 2021</strong></em> <strong><font color="#ff0000">(Long Talk, Top 3%)</font></strong> <br>
                [<a href="https://arxiv.org/pdf/2106.02890.pdf" target="_blank">PDF</a>]
                [<a href="javascript:togglebib('zhang2021can')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{zhang2021can,
                        title={Can subnetwork structure be the key to out-of-distribution generalization?},
                        author={Zhang, Dinghuai and Ahuja, Kartik and Xu, Yilun and Wang, Yisen and Courville, Aaron},
                        booktitle={ICML},
                        year={2021}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="2021 SSL">
              <div class="text" id="wen2021leveraged">
              <ul>
                <li><strong>Leveraged Weighted Loss for Partial Label Learning</strong>  <br>
                Hongwei Wen*, Jingyi Cui*, Hanyuan Hang, Jiabin Liu#, <strong>Yisen Wang#</strong>, Zhouchen Lin#<br>
                <em><strong>ICML 2021</strong></em> <strong><font color="#ff0000">(Long Talk, Top 3%)</font></strong> <br>
                [<a href="https://arxiv.org/pdf/2106.05731.pdf" target="_blank">PDF</a>]
                [<a href="https://github.com/hongwei-wen/LW-loss-for-partial-label" target="_blank">Code</a>]
                [<a href="javascript:togglebib('wen2021leveraged')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{wen2021leveraged,
                        title={Leveraged weighted loss for partial label learning},
                        author={Wen, Hongwei and Cui, Jingyi and Hang, Hanyuan and Liu, Jiabin and Wang, Yisen and Lin, Zhouchen},
                        booktitle={ICML},
                        year={2021}}
                </pre>
              </li>
              </ul>
              </div>
            </div>

            <div class="2021 SSL">
              <div class="text" id="cui2021gbht">
              <ul>
                <li><strong>GBHT: Gradient Boosting Histogram Transform for Density Estimation</strong>  <br>
                Jingyi Cui*, Hanyuan Hang*, <strong>Yisen Wang#</strong>, Zhouchen Lin<br>
                <em><strong>ICML 2021</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://arxiv.org/pdf/2106.05738.pdf" target="_blank">PDF</a>]
                [<a href="javascript:togglebib('cui2021gbht')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{cui2021gbht,
                        title={GBHT: Gradient Boosting Histogram Transform for Density Estimation},
                        author={Cui, Jingyi and Hang, Hanyuan and Wang, Yisen and Lin, Zhouchen},
                        booktitle={ICML},
                        year={2021}}
                </li>
              </ul>
              </div>
            </div>

            <div class="2021 Adv">
              <div class="text" id="tian2021analysis">
              <ul>
                <li><strong>Analysis and Applications of Class-wise Robustness in Adversarial Training</strong>  <br>
                Qi Tian, Kun Kuang#, Kelu Jiang, Fei Wu, <strong>Yisen Wang#</strong><br>
                <em><strong>KDD 2021</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://arxiv.org/pdf/2105.14240.pdf" target="_blank">PDF</a>]
                [<a href="javascript:togglebib('tian2021analysis')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{tian2021analysis,
                        title={Analysis and Applications of Class-wise Robustness in Adversarial Training},
                        author={Tian, Qi and Kuang, Kun and Jiang, Kelu and Wu, Fei and Wang, Yisen},
                        booktitle={KDD},
                        year={2021}}
                </li>
              </ul>
              </div>
            </div>

            <div class="selected 2021 Adv">
              <div class="text" id="huang2021unlearnable">
              <ul>
                <li><strong>Unlearnable Examples: Making Personal Data Unexploitable</strong>  <br>
                Hanxun Huang, Xingjun Ma#, Sarah Monazam Erfani, James Bailey, <strong>Yisen Wang#</strong><br>
                <em><strong>ICLR 2021</strong></em> <strong><font color="#ff0000">(Spotlight, Top 4%, Featured by MIT Technology Review)</font></strong> <br>
                [<a href="https://openreview.net/pdf?id=iAmZUo0DxC0" target="_blank">PDF</a>]
                [<a href="https://github.com/HanxunH/Unlearnable-Examples" target="_blank">Code</a>]
                [<a href="https://www.technologyreview.com/2021/05/05/1024613/stop-ai-recognizing-your-face-selfies-machine-learning-facial-recognition-clearview/">MIT Technology Review</a>]
                [<a href="javascript:togglebib('huang2021unlearnable')">Bib</a>]<br>
                <pre style="display: none">
                        @inproceedings{huang2021unlearnable,
                        title={Unlearnable Examples: Making Personal Data Unexploitable},
                        author={Huang, Hanxun and Ma, Xingjun and Erfani, Sarah Monazam and Bailey, James and Wang, Yisen},
                        booktitle={ICLR},
                        year={2021}}
                </li>
              </ul>
              </div>
            </div>

            <div class="2021 Adv">
              <div class="text" id="bai2021improving">
              <ul>
                <li><strong>Improving Adversarial Robustness via Channel-wise Activation Suppressing</strong>  <br>
                Yang Bai*, Yuyuan Zeng*, Yong Jiang, Shu-Tao Xia#, Xingjun Ma, <strong>Yisen Wang#</strong><br>
                <em><strong>ICLR 2021</strong></em> <strong><font color="#ff0000">(Spotlight, Top 4%)</font></strong> <br>
                [<a href="https://arxiv.org/pdf/2103.08307.pdf" target="_blank">PDF</a>]
                [<a href="https://github.com/bymavis/CAS_ICLR2021" target="_blank">Code</a>]
                [<a href="javascript:togglebib('bai2021improving')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{bai2021improving,
                        title={Improving adversarial robustness via channel-wise activation suppressing},
                        author={Bai, Yang and Zeng, Yuyuan and Jiang, Yong and Xia, Shu-Tao and Ma, Xingjun and Wang, Yisen},
                        booktitle={ICLR},
                        year={2021}}
                </li>
              </ul>
              </div>
            </div>

            <div class="2021 Adv">
              <div class="text" id="wang2021unified">
              <ul>
                <li><strong>A Unified Approach to Interpreting and Boosting Adversarial Transferability</strong>  <br>
                Xin Wang*, Jie Ren*, Shuyun Lin, Xiangming Zhu, <strong>Yisen Wang</strong>, Quanshi Zhang<br>
                <em><strong>ICLR 2021</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://openreview.net/pdf?id=X76iqnUbBjz" target="_blank">PDF</a>]
                [<a href="https://github.com/xherdan76/A-Unified-Approach-to-Interpreting-and-Boosting-Adversarial-Transferability" target="_blank">Code</a>]
                [<a href="https://zhuanlan.zhihu.com/p/264873308/" target="_blank">Zhihu</a>]
                [<a href="javascript:togglebib('wang2021unified')">Bib</a>]<br>
                <pre style="display: none">
                        @inproceedings{wang2021unified,
                          title={A unified approach to interpreting and boosting adversarial transferability},
                          author={Wang, Xin and Ren, Jie and Lin, Shuyun and Zhu, Xiangming and Wang, Yisen and Zhang, Quanshi},
                          booktitle={ICLR},
                          year={2021}}
                </li>
              </ul>
              </div>
            </div>

            <div class="selected 2020 Adv">
              <div class="text" id="wu2020adversarial">
              <ul>
                <li><strong>Adversarial Weight Perturbation Helps Robust Generalization</strong>  <br>
                Dongxian Wu, Shu-Tao Xia, <strong>Yisen Wang#</strong><br>
                <em><strong>NeurIPS 2020</strong></em> <strong><font color="#ff0000">(Rank 1st in CVPR 2021 Competitions)</font></strong> <br>
                [<a href="https://arxiv.org/pdf/2004.05884.pdf" target="_blank">PDF</a>]
                [<a href="https://github.com/csdongxian/AWP" target="_blank">Code</a>]
                [<a href="https://www.bilibili.com/video/BV1pt4y1Y7uU" target="_blank">NeurIPS MeetUp Video</a>]
                [<a href="https://ml.cs.tsinghua.edu.cn/adv-bench/#/" target="_blank">CVPR 2021 Competitions</a>]
                [<a href="https://github.com/PaddlePaddle/PaddleSleeve" target="_blank">PaddlePaddle</a>]
                [<a href="javascript:togglebib('wu2020adversarial')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{wu2020adversarial,
                        title={Adversarial Weight Perturbation Helps Robust Generalization},
                        author={Wu, Dongxian and Xia, Shu-Tao and Wang, Yisen},
                        booktitle={NeurIPS},
                        year={2020}}
                </li>
              </ul>
              </div>
            </div>

            <div class="2020 SSL">
              <div class="text" id="ma2020normalized">
              <ul>
                <li><strong>Normalized Loss Functions for Deep Learning with Noisy Labels</strong>  <br>
                Xingjun Ma*, Hanxun Huang*, <strong>Yisen Wang#</strong>, Simone Romano, Sarah Erfani and James Bailey<br>
                <em><strong>ICML 2020</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://arxiv.org/abs/2006.13554" target="_blank">PDF</a>]
                [<a href="https://github.com/HanxunHuangLemonBear/Active-Passive-Losses" target="_blank">Code</a>]
                [<a href="javascript:togglebib('ma2020normalized')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{ma2020normalized,
                        title={Normalized loss functions for deep learning with noisy labels},
                        author={Ma, Xingjun and Huang, Hanxun and Wang, Yisen and Romano, Simone and Erfani, Sarah and Bailey, James},
                        booktitle={ICML},
                        year={2020}}
                </li>
              </ul>
              </div>
            </div>

            <div class="selected 2020 Adv">
              <div class="text" id="wang2020improving">
              <ul>
                <li><strong>Improving Adversarial Robustness Requires Revisiting Misclassified Examples</strong>  <br>
                <strong>Yisen Wang*</strong>, Difan Zou*, Jinfeng Yi, James Bailey, Xingjun Ma, Quanquan Gu<br>
                <em><strong>ICLR 2020</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://openreview.net/pdf?id=rklOg6EFwS" target="_blank">PDF</a>]
                [<a href="https://github.com/YisenWang/MART" target="_blank">Code</a>]
                [<a href="javascript:togglebib('wang2020improving')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{wang2020improving,
                      title={Improving Adversarial Robustness Requires Revisiting Misclassified Examples},
                      author={Yisen Wang and Difan Zou and Jinfeng Yi and James Bailey and Xingjun Ma and Quanquan Gu},
                      booktitle={ICLR},
                      year={2020}}
                </li>
              </ul>
              </div>
            </div>

            <div class="selected 2020 Adv">
              <div class="text" id="wu2020skip">
              <ul>
                <li><strong>Skip Connections Matter: On the Transferability of Adversarial Examples Generated with ResNets</strong>  <br>
                Dongxian Wu, <strong>Yisen Wang#</strong>, Shu-Tao Xia, James Bailey, Xingjun Ma<br>
                <em><strong>ICLR 2020</strong></em> <strong><font color="#ff0000">(Spotlight, Top 4%)</font></strong> <br>
                [<a href="https://openreview.net/pdf?id=BJlRs34Fvr" target="_blank">PDF</a>]
                [<a href="https://github.com/csdongxian/skip-connections-matter" target="_blank">Code</a>]
                [<a href="javascript:togglebib('wu2020skip')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{wu2020skip,
                      title={Skip Connections Matter: On the Transferability of Adversarial Examples Generated with ResNets},
                      author={Dongxian Wu and Yisen Wang and Shu-Tao Xia and James Bailey and Xingjun Ma},
                      booktitle={ICLR},
                      year={2020}}
                </li>
              </ul>
              </div>
            </div>

            <div class="2020 Adv">
              <div class="text" id="duan2020adversarial">
              <ul>
                <li><strong>Adversarial Camouflage: Hiding Physical-World Attacks with Natural Styles</strong>  <br>
                Ranjie Duan, Xingjun Ma, <strong>Yisen Wang</strong>, James Bailey, Kai Qin, Yun Yang<br>
                <em><strong>CVPR 2020</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://arxiv.org/abs/2003.08757" target="_blank">PDF</a>]
                [<a href="https://github.com/RjDuan/AdvCam-Hide-Adv-with-Natural-Styles" target="_blank">Code</a>]
                [<a href="javascript:togglebib('duan2020adversarial')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{duan2020adversarial,
                        title={Adversarial Camouflage: Hiding Physical-World Attacks with Natural Styles},
                        author={Duan, Ranjie and Ma, Xingjun and Wang, Yisen and Bailey, James and Qin, A Kai and Yang, Yun},
                        booktitle={CVPR},
                        year={2020}}
                </li>
              </ul>
              </div>
            </div>

            <div class="2020 Adv">
              <div class="text" id="bai2020improving">
              <ul>
                <li><strong>Improving Query Efficiency of Black-box Adversarial Attack</strong>  <br>
                Yang Bai*, Yuyuan Zeng*, Yong Jiang#, <strong>Yisen Wang#</strong>, Shu-Tao Xia, Weiwei Guo<br>
                <em><strong>ECCV 2020</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://arxiv.org/pdf/2009.11508.pdf" target="_blank">PDF</a>]
                [<a href="https://github.com/Sandy-Zeng/NPAttack" target="_blank">Code</a>]
                [<a href="javascript:togglebib('bai2020improving')">Bib</a>]<br>
                <pre style="display: none">
                        @inproceedings{bai2020improving,
                          title={Improving query efficiency of black-box adversarial attack},
                          author={Bai, Yang and Zeng, Yuyuan and Jiang, Yong and Wang, Yisen and Xia, Shu-Tao and Guo, Weiwei},
                          booktitle={ECCV},
                          year={2020}}
                </li>
              </ul>
              </div>
            </div>

            <div class="2020 Adv">
              <div class="text" id="ma2019understanding">
              <ul>
                <li><strong>Understanding Adversarial Attacks on Deep Learning Based Medical Image Analysis Systems</strong>  <br>
                Xingjun Ma, Yuhao Niu, Lin Gu, <strong>Yisen Wang</strong>, Yitian Zhao, James Bailey, Feng Lu <br>
                <em><strong>Pattern Recognition, 2020</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://www.sciencedirect.com/science/article/pii/S0031320320301357" target="_blank">PDF</a>]
                [<a href="https://github.com/zzdyyy/Understanding-Adversarial-Attacks-MIA" target="_blank">Code</a>]
                [<a href="https://www.rsipvision.com/ComputerVisionNews-2020October/4/">Computer Vision News</a>]
                [<a href="javascript:togglebib('ma2019understanding')">Bib</a>]<br>
                <pre style="display: none">
                        @article{ma2019understanding,
                          title={Understanding Adversarial Attacks on Deep Learning Based Medical Image Analysis Systems},
                          author={Ma, Xingjun and Niu, Yuhao and Gu, Lin and Wang, Yisen and Zhao, Yitian and Bailey, James and Lu, Feng},
                          journal={Pattern Recognition},
                          year={2020}}
                </li>
              </ul>
              </div>
            </div>

            <div class="selected 2019 Adv">
              <div class="text" id="wang2019dynamic">
              <ul>
                <li><strong>On the Convergence and Robustness of Adversarial Training</strong>  <br>
                <strong>Yisen Wang*</strong>, Xingjun Ma*, James Bailey, Jinfeng Yi, Bowen Zhou, Quanquan Gu<br>
                <em><strong>ICML 2019</strong></em> <strong><font color="#ff0000">(Long Talk, Top 3%)</font></strong> <br>
                [<a href="https://arxiv.org/pdf/2112.08304.pdf" target="_blank">PDF</a>]
                [<a href="https://github.com/YisenWang/dynamic_adv_training" target="_blank">Code</a>]
                [<a href="javascript:togglebib('wang2019dynamic')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{wang2019dynamic,
                        title={On the Convergence and Robustness of Adversarial Training},
                        author={Wang, Yisen and Ma, Xingjun and Bailey, James and Yi, Jinfeng and Zhou, Bowen and Gu, Quanquan},
                        booktitle={ICML},
                        year={2019}}
                </li>
              </ul>
              </div>
            </div>

            <div class="selected 2019 SSL">
              <div class="text" id="wang2019symmetric">
              <ul>
                <li><strong>Symmetric Cross Entropy for Robust Learning with Noisy Labels</strong>  <br>
                <strong>Yisen Wang*</strong>, Xingjun Ma*, Zaiyi Chen, Yuan Luo, Jinfeng Yi, James Bailey<br>
                <em><strong>ICCV 2019</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://arxiv.org/abs/1908.06112" target="_blank">PDF</a>]
                [<a href="https://github.com/YisenWang/symmetric_cross_entropy_for_noisy_labels" target="_blank">Code</a>]
                [<a href="javascript:togglebib('wang2019symmetric')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{wang2019symmetric,
                        title={Symmetric cross entropy for robust learning with noisy labels},
                        author={Wang, Yisen and Ma, Xingjun and Chen, Zaiyi and Luo, Yuan and Yi, Jinfeng and Bailey, James},
                        booktitle={ICCV},
                        year={2019}}
                </li>
              </ul>
              </div>
            </div>

            <div class="2019 Adv">
              <div class="text" id="bai2019hilbert">
              <ul>
                <li><strong>Hilbert-Based Generative Defense for Adversarial Examples</strong>  <br>
                Yang Bai*, Yan Feng*, <strong>Yisen Wang#</strong>, Shu-Tao Xia, Yong Jiang#<br>
                <em><strong>ICCV 2019</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Bai_Hilbert-Based_Generative_Defense_for_Adversarial_Examples_ICCV_2019_paper.pdf" target="_blank">PDF</a>]
                [<a href="javascript:togglebib('bai2019hilbert')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{bai2019hilbert,
                        title={Hilbert-Based Generative Defense for Adversarial Examples},
                        author={Bai, Yang and Feng, Yan and Wang, Yisen and Dai, Tao and Xia, Shu-Tao and Jiang, Yong},
                        booktitle={ICCV},
                        year={2019}}
                </li>
              </ul>
              </div>
            </div>

            <div class="selected 2018 SSL">
              <div class="text" id="wang2018iterative">
              <ul>
                <li><strong>Iterative Learning with Open-set Noisy Labels</strong>  <br>
                <strong>Yisen Wang</strong>, Weiyang Liu, Xingjun Ma, James Bailey, Hongyuan Zha, Le Song, Shu-Tao Xia<br>
                <em><strong>CVPR 2018</strong></em> <strong><font color="#ff0000">(Spotlight, Top 7%)</font></strong> <br>
                [<a href="https://arxiv.org/pdf/1804.00092.pdf" target="_blank">PDF</a>]
                [<a href="https://github.com/YisenWang/ONL" target="_blank">Code</a>]
                [<a href="javascript:togglebib('wang2018iterative')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{wang2018iterative,
                        title={Iterative learning with open-set noisy labels},
                        author={Wang, Yisen and Liu, Weiyang and Ma, Xingjun and Bailey, James and Zha, Hongyuan and Song, Le and Xia, Shu-Tao},
                        booktitle={CVPR},
                        year={2018}}
                </li>
              </ul>
              </div>
            </div>

            <div class="selected 2018 SSL">
              <div class="text" id="ma2018dimensionality">
              <ul>
                <li><strong>Dimensionality-Driven Learning with Noisy Labels</strong>  <br>
                Xingjun Ma*, <strong>Yisen Wang*</strong>, Michael E. Houle, Shuo Zhou, Sarah Monazam Erfani, Shu-Tao Xia, Sudanthi Wijewickrema, James Bailey<br>
                <em><strong>ICML 2018</strong></em> <strong><font color="#ff0000">(Long Talk, Top 3%)</font></strong> <br>
                [<a href="https://arxiv.org/pdf/1806.02612.pdf" target="_blank">PDF</a>]
                [<a href="https://github.com/xingjunm/dimensionality-driven-learning" target="_blank">Code</a>]
                [<a href="javascript:togglebib('ma2018dimensionality')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{ma2018dimensionality,
                        title={Dimensionality-driven learning with noisy labels},
                        author={Ma, Xingjun and Wang, Yisen and Houle, Michael E and Zhou, Shuo and Erfani, Sarah and Xia, Shutao and Wijewickrema, Sudanthi and Bailey, James},
                        booktitle={ICML},
                        year={2018}}
                </li>
              </ul>
              </div>
            </div>

            <div class="2018 Adv">
              <div class="text" id="ma2018characterizing">
              <ul>
                <li><strong>Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality</strong>  <br>
                Xingjun Ma, Bo Li, <strong>Yisen Wang</strong>, Sarah M. Erfani, Sudanthi Wijewickrema, Michael E. Houle, Grant Schoenebeck, Dawn Song, James Bailey<br>
                <em><strong>ICLR 2018</strong></em> <strong><font color="#ff0000">(Oral, Top 2%)</font></strong> <br>
                [<a href="https://arxiv.org/pdf/1801.02613.pdf" target="_blank">PDF</a>]
                [<a href="https://github.com/xingjunm/lid_adversarial_subspace_detection" target="_blank">Code</a>]
                [<a href="javascript:togglebib('ma2018characterizing')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{ma2018characterizing,
                        title={Characterizing adversarial subspaces using local intrinsic dimensionality},
                        author={Ma, Xingjun and Li, Bo and Wang, Yisen and Erfani, Sarah M and Wijewickrema, Sudanthi and Schoenebeck, Grant and Song, Dawn and Houle, Michael E and Bailey, James},
                        booktitle={ICLR},
                        year={2018}}
                </li>
              </ul>
              </div>
            </div>

            <div class="2018 SSL">
              <div class="text" id="Liu2018DCNets">
              <ul>
                <li><strong>Decoupled Networks</strong>  <br>
                Weiyang Liu, Zhen Liu, Zhiding Yu, Bo Dai, Rongmei Lin, <strong>Yisen Wang</strong>, James Rehg, Le Song<br>
                <em><strong>CVPR 2018</strong></em> <strong><font color="#ff0000">(Spotlight, Top 7%)</font></strong> <br>
                [<a href="https://arxiv.org/pdf/1804.08071.pdf" target="_blank">PDF</a>]
                [<a href="https://github.com/wy1iu/DCNets" target="_blank">Code</a>]
                [<a href="javascript:togglebib('Liu2018DCNets')">Bib</a>]<br>
                <pre style="display: none">
                      @inproceedings{Liu2018DCNets,
                          author = {Liu, Weiyang and Liu, Zhen and Yu, Zhiding and Dai, Bo and Lin, Rongmei
                           and Wang, Yisen and Rehg, James M. and Song, Le},
                          title = {Decoupled Networks},
                          booktitle = {CVPR},
                          year = {2018}}
                </li>
              </ul>
              </div>
            </div>



            <div class="2018">
              <div class="text" id="wang2017novel">
              <ul>
                <li><strong>A Novel Consistent Random Forest Framework: Bernoulli Random Forests</strong>  <br>
                <strong>Yisen Wang</strong>, Shu-Tao Xia, Qingtao Tang, Jia Wu, Xingquan Zhu <br>
                <em><strong>IEEE Transactions on Neural Networks and Learning Systems, 2018</strong></em> <strong><font color="#ff0000"></font></strong> <br>
                [<a href="http://www.cse.fau.edu/~xqzhu/papers/TNN.Wang.2017.Forest.pdf" target="_blank">PDF</a>]
                [<a href="javascript:togglebib('wang2017novel')">Bib</a>]<br>
                <pre style="display: none">
                      @article{wang2017novel,
                        title={A novel consistent random forest framework: Bernoulli random forests},
                        author={Wang, Yisen and Xia, Shu-Tao and Tang, Qingtao and Wu, Jia and Zhu, Xingquan},
                        journal={IEEE Transactions on Neural Networks and Learning Systems},
                        volume={29},
                        number={8},
                        pages={3510--3523},
                        year={2018},
                        publisher={IEEE}}
                </li>
              </ul>
              </div>
            </div>

        </div>


        </div>  <!-- content -->

        <div class="content front">
          <div class="text">
            <h3 style="margin-bottom:.5em">Talks</h3>
            <ul>
              <li>Invited Talk, <a href="https://icml-tifa.github.io/" target="_blank">ICML 2024 Workshop on Trustworthy Multi-modal Foundation Models and AI Agents</a>, Vienna, Austria</li>
              <li>Invited Talk, <a href="https://dl2024.casconf.cn/page/1800418071320596481" target="_blank">International Conference on Mathematical Theory of Deep Learning</a>, Beijing, China</li>
              <li>Invited Talk, <a href="https://valser.org/2024/#/workshopde?id=5" target="_blank">VALSE 2024 Workshop on Model Security</a>, Chongqing, China</li>
              <li>Invited Talk, <a href="https://iccv23-arow.github.io/" target="_blank">ICCV 2023 Workshop on Adversarial Robustness In the Real World</a>, Paris, France</li>
              <li>Invited Talk, <a href="https://trustml.ubc.ca/events/trustml-workshop-ubc-june-2023" target="_blank">TrustML Workshop @UBC</a>, Vancouver, Canada</li>
              <li>Invited Talk, <a href="http://icig2023.csig.org.cn/workshops/" target="_blank">ICIG 2023 Workshop on Machine Vision and Learning</a>, Nanjing, China</li>
              <li>Invited Talk, <a href="https://practical-dl.github.io/2022/index" target="_blank">AAAI 2022 Workshop on Practical Deep Learning in the Wild</a></li>
              <li>Panelist, <a href="https://advml-workshop.github.io/icml2021/" target="_blank">ICML 2021 Workshop on Adversarial Machine Learning</a></li>
              <li>Invited Talk, <a href="https://aisecure-workshop.github.io/amlcvpr2021/" target="_blank">CVPR 2021 Workshop on Adversarial Machine Learning in Real-World Computer Vision Systems and Online Challenges (AML-CV)</a></li>
              <li>Panelist, <a href="http://valser.org/2021/#/workshopde?id=6" target="_blank">VALSE 2021 Workshop on Frontiers of Machine Learning</a></li>
              <li>VALSE Tutorial: Adversarial Attack and Defense</strong> (in Chinese) [<a href="https://www.bilibili.com/video/BV1Pf4y1c7dg/?spm_id_from=333.999.0.0" target="_blank">Video</a>] [<a href="https://mp.weixin.qq.com/s/-lzPJFRmRhgqfJp4ckqMCw" target="_blank">Note</a>]</li>
<!--              <li>Keynote & Chair, <a href="https://event.baai.ac.cn/activities/131" target="_blank">BAAI Seminar for Pretalk of ICLR 2021 in China</a></li>-->
              <li>Invited Talk, <a href="https://ccfai2021.ytu.edu.cn/xsztlt.htm" target="_blank">CCFAI 2021 Young Scholars Forum</a></li>
              <li>Invited Talk, <a href="http://csee.hnu.edu.cn/ccdm2020/xsztlt.html" target="_blank">CCDM 2020 Workshop on Data Mining and Learning</a></li>
              <li>Guest Lecture, <a href="https://courses.grainger.illinois.edu/cs498lb1/sp2021/" target="_blank">CS498: Trustworthy Machine Learning@UIUC </a></li>
            </ul>
          </div>
        </div>

        <div class="content front">
          <div class="text">
            <h3 style="margin-bottom:.5em">Service</h3>
            <ul>
              <li>Senior Area Chair: NeurIPS 2024/2025</li>
              <li>Area Chair: ICML/NeurIPS/ICLR/CVPR/AISTATS (regularly)</li>
              <li>Workshop Organizer: <a href="https://redteaming-gen-ai.github.io/" target="_blank">NeurIPS 2024 Workshop</a>, <a href="https://set-llm.github.io/" target="_blank">ICLR 2024 Workshop</a>, <a href="https://iccv23-arow.github.io/" target="_blank">ICCV 2023 Workshop</a></li>
<!--              <li></li>-->

            </ul>
          </div>
        </div>

        <div class="content front">
          <div class="text">
            <h3 style="margin-bottom:.5em">Awards</h3>
            <ul>
                <li><a href="https://mp.weixin.qq.com/s/1OhZ3j4XIdLWC8nNPk6P8A" target="_blank">CAA First Prize of Natural Science Award (2/5)</a>, 2024</li>
                <li><a href="https://mp.weixin.qq.com/s/f3ovMYxcdhWZ8i2Y0PC0KQ" target="_blank">Supervisor of CAA Outstanding Ph.D. Dissertation Award</a>, 2024</li>
                <li><a href="https://iclworkshop.github.io/" target="_blank">Spotlight Award (Best Paper)</a>, ICML 2024 Workshop on In-Context Learning, 2024</li>
                <li>Supervisor of Peking University Outstanding Undergraduate Dissertation Award, 2024</li>
                <li>Supervisor of CAAI Outstanding Ph.D. Dissertation Runner-Up Award, 2023</li>
                <li><a href="https://elsevier.digitalcommonsdata.com/datasets/btchxktzyw/6" target="_blank">World's Top 2% Scientists</a>, 2023/2024</li>
                <li><a href="./NeurIPS_Notable_AC.pdf" target="_blank">NeurIPS Notable Area Chair</a>, 2023</li>
                <li>Beijing Nova Talent Program, 2023</li>
                <li>ACM Beijing Rising Star Award, 2023</li>
                <li><a href="https://www.cis.pku.edu.cn/info/1082/2638.htm" target="_blank">First Prize</a>, 22nd Teaching Competition&nbsp;of Peking University, 2022</li>
                <li><a href="https://2021.ecmlpkdd.org/index.html@p=2148.html" target="_blank">Best (Student) Paper Award</a>, ECML-PKDD 2021 (1/685)&nbsp;</li>
                <li><a href="https://advml-workshop.github.io/icml2021/" target="_blank">Silver Best Paper Award</a>, ICML 2021 Workshop on Adversarial Machine Learning</li>
                <li><a href="https://ml.cs.tsinghua.edu.cn/adv-bench/#/" target="_blank">1st Place Defense Method</a>, CVPR 2021 Competition of White-box Adversarial Attacks on ML Defense Models </li>
                <li><a href="http://hof.geekpwn.org/zh/index.html" target="_blank">Champion</a>, 2020 GeekPwn CAAD AI MASK Competitions </li>
                <li><a href="http://scholarship.baidu.com/" target="_blank">Baidu Scholarship</a> (only 10 world-wide per year)&nbsp;</li>
                <li><a href="https://www.acmturc.com/2021/en/doctoral_thesis_award.html" target="_blank">ACM China Doctoral Dissertation Award Honorable Mention</a> (only 5 nation-wide per year)</li>
                <li>Outstanding Doctoral Dissertation Award of Tsinghua University </li>
                <li><a href="https://www.msra.cn/zh-cn/connections/academic-programs/fellows" target="_blank">Microsoft Research Fellowship Nomination Award</a></li>
<!--                <li><a href="http://phdforum.se.cuhk.edu.hk/2016/content/bestpaper.html" target="_blank">Best Paper Award</a>, 9th International Doctoral Forum (Hong Kong)</li>-->
<!--                <li>National Scholarship for Ph.D. Student</li>-->
<!--                <li>Lixin Tang Scholarship of Tsinghua University</li>-->
                <li>Top 10 Undergraduate Excellence Award (only 10 awardees university-wide per year)</li>
<!--                <li>Meritorious Winner (First Prize) of MCM: The Mathematical Contest in Modeling</li>-->
<!--                <li>National Scholarship for Undergraduate Student</li>-->
              </ul>
          </div>
        </div>


      </div> <!-- container -->




    </div> <!-- outer container -->

    <script>var scroll = new SmoothScroll('a[href*="#"]', {speed: 1000});</script>
    <script>showPubs(0);</script>


  </body>

</html>
