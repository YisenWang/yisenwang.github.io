<blockquote>

<table border="0">

<tbody>

<tr>

<td style="width:227px;height:415px">
<div align="center" src="">

<div align="left"><a href="https://yisenwang.github.io/"><img alt="Yisen Wang" border="2" height="320" hspace="0" src="https://yisenwang.github.io/yisenwang.jpg" vspace="0" width="213"></a></div>
        </div>
</td>

<td style="width:525px;height:415px">
<p><span><font size="5"><a href="https://yisenwang.github.io/">Yisen Wang 王奕森</a></font></span><br>
<font size="4">
            Assistant Professor, Ph.D. Advisor <br>
            School of EECS, Peking University </font><br>
            <br>
<font size="3">
            Room 2201, Science Building #2 <br>
            Peking University, Beijing 100871, China </font><br>
            <br>
<font size="3">
            Email: yisen.wang AT pku DOT edu.cn&nbsp;<br>
            Homepage (Overseas): <a href="https://sites.google.com/site/csyisenwang/" target="_blank">https://sites.google.com/site/csyisenwang/</a><br>
            Homepage (Wall-inside): <a href="https://yisenwang.github.io/">https://yisenwang.github.io/</a><br>
            Official Website: <a href="http://www.cis.pku.edu.cn/info/1084/1244.htm" target="_blank">http://www.cis.pku.edu.cn/info/1084/1244.htm</a>&nbsp;</font></p>
<p><font size="3">
<span>[<a href="https://scholar.google.com/citations?user=uMWPDboAAAAJ&amp;hl=en" target="_blank">Google Scholar</a>] </span><span> [<a href="https://github.com/YisenWang" target="_blank">Github</a>]</span></font><br>
            <span><br>
            </span><span><br>
        </span></p>
</td>
      </tr>
    </tbody>
  </table>

<hr>

<p align="justify"><span><span style="font-size:22pt"><b><span style="font-family:Monotype Corsiva;COLOR:green"><a name="Bio"></a><span>Biography</span></span></b></span></span><br>
    <br>
    <span>I am now a Tenure-track Assistant Professor (Ph.D. Advisor) in Department of Machine Intelligence, <a href="https://eecs.pku.edu.cn/">School of Electronics Engineering and Computer Science (EECS)</a>, <a href="https://www.pku.edu.cn/">Peking University</a>. I am also a faculty member of <a href="https://zero-lab-pku.github.io/people/" target="_blank">ZERO Lab at Peking University</a> led by <a href="https://zhouchenlin.github.io/" target="_blank">Prof. Zhouchen Lin</a>. </span></p>

<p align="justify"><span>
I got my PhD degree from <a href="http://www.cs.tsinghua.edu.cn/">Department of Computer Science and Technology</a>, <a href="https://www.tsinghua.edu.cn/">Tsinghua University</a>. I have visited <a href="https://www.gatech.edu/">Georgia Tech</a>, USA, hosted by <a href="https://www.cc.gatech.edu/~lsong/" target="_blank">Prof. Le Song</a> and <a href="https://www.cc.gatech.edu/~zha/" target="_blank">Prof. Hongyuan Zha</a>, and <a href="https://www.unimelb.edu.au/">The University of Melbourne</a>, Australia, hosted by <a href="https://people.eng.unimelb.edu.au/baileyj/" target="_blank">Prof. James Bailey</a>.&nbsp;</span></p>

<p align="justify"><span>My research interest broadly includes the theory and applications of machine learning and deep learning, such as adversarial learning, graph learning, and weakly/self-supervised learning.</span></p>


<hr>

<p align="justify"><span><span style="font-size:22pt"><b><span style="font-family:Monotype Corsiva;COLOR:green"><a name="Bio"></a><span>Openings</span></span></b></span></span><br>
    </p>
<p align="justify"><span style="color:#ff0000"><b>We are recruiting highly motivated post-docs via <a href="https://postdocs.pku.edu.cn/index.htm" target="_blank">Peking University Boya Postdoctoral Fellowship</a> (Salary 350K+) </b></span></p>

<p align="justify"><span style="color:#ff0000"><b>We are always actively recruiting Ph.D. students and interns! Welcome to contact me with your detailed CV! </b></span></p>

<hr>

<p align="justify"><span><span style="font-size:22pt"><b><span style="font-family:Monotype Corsiva;COLOR:green"><a name="Bio"></a><span>News</span></span></b></span></span><br>
    </p>
<ul>
<li>5/2021, Three papers were accepted to ICML 2021 (Two are <b><font color="#ff0000">Long Talk</font></b>, <font color="#000000">Top 3% =&nbsp;166/5513</font>).</li>
<li>5/2021, One paper was accepted to KDD 2021. </li>
<li>3/2021, I will serve as Area Chair of NeurIPS 2021. </li>
<li>1/2021, Three papers were accepted to ICLR 2021 (Two are <b><font color="#ff0000">Spotlight</font></b>, <font color="#000000">Top 4% =&nbsp;114/2997</font>).</li>
<li>10/2020, Our team (Dongxian Wu, Yisen Wang (advisor), Yanjie Li, Bin Chen) won <font color="red"><b>the first prize</b></font> in the <a href="http://hof.geekpwn.org/zh/index.html" target="_blank">2020 GeekPwn CAAD AI MASK</a> competitions.</li>
<li>10/2020, I will serve as Senior PC for IJCAI 2021.&nbsp;</li>
<li>9/2020, One paper was accepted to NeurIPS 2020.&nbsp;</li>
</ul>

<hr>


<p align="justify"><span><span style="font-size:22pt"><b><span style="font-family:Monotype Corsiva;COLOR:green"><a name="Bio"></a><span>Publications</span></span></b></span></span></p>

<p><span style="background-color:transparent;font-family:Monotype Corsiva;color:rgb(51,51,51)"><strong>(&nbsp;</strong></span><strong style="background-color:transparent;text-align:justify">*&nbsp;</strong><strong style="background-color:transparent;color:rgb(51,51,51);font-family:Monotype Corsiva">Equal&nbsp; Contribution;&nbsp;&nbsp;</strong><strong style="background-color:transparent;text-align:justify">#&nbsp;</strong><strong style="background-color:transparent;color:rgb(51,51,51);font-family:Monotype Corsiva">Corresponding&nbsp; Author)</strong></p>
<table border="0" bordercolor="#FF0000" cellpadding="1" cellspacing="1" height="130" width="101%">

<tbody>

<tr>

<td>
<ol>

<li>
<div align="justify">
<p><strong>Can Subnetwork Structure be the Key to Out-of-Distribution Generalization?</strong> <br>
                Dinghuai Zhang, Kartik Ahuja, Yilun Xu, <strong>Yisen Wang</strong>, Aaron Courville<br>
                <em>International Conference on Machine Learning (<strong>ICML 2021</strong>), 2021&nbsp;</em><span style="background-color:transparent;text-align:left">(</span><strong style="background-color:transparent;text-align:left"><font color="#ff0000">Long Talk, Top 3%</font></strong><span style="background-color:transparent;text-align:left">)</span>
</p>
</div>
</li>

<li>
<div align="justify">
<p><strong>Leveraged Weighted Loss for Partial Label Learning</strong> <br>
                Hongwei Wen*, Jingyi Cui*, Hanyuan Hang, Jiabin Liu#, <strong>Yisen Wang#</strong>, Zhouchen Lin<br>
                <em>International Conference on Machine Learning (<strong>ICML 2021</strong>), 2021&nbsp;</em><span style="background-color:transparent;text-align:left">(</span><strong style="background-color:transparent;text-align:left"><font color="#ff0000">Long Talk, Top 3%</font></strong><span style="background-color:transparent;text-align:left">)</span>
</p>
</div>
</li>

<li>
<div align="justify">
<p><strong>GBHT: Gradient Boosting Histogram Transform for Density Estimation</strong> <br>
                Jingyi Cui*, Hanyuan Hang*, <strong>Yisen Wang#</strong>, Zhouchen Lin<br>
                <em>International Conference on Machine Learning (<strong>ICML 2021</strong>), 2021&nbsp;</em><br>
</p>
</div>
</li>

<li>
<div align="justify">
<p><strong>Analysis and Applications of Class-wise Robustness in Adversarial Training</strong> <br>
                Qi Tian, Kun Kuang#, Kelu Jiang, Fei Wu, <strong>Yisen Wang#</strong><br>
                <em>ACM SIGKDD Conference on Knowledge Discovery and Data Mining (<strong>KDD 2021</strong>), 2021&nbsp;</em><br>
</p>
</div>
</li>

<li>
<div align="justify">
<p><strong>Unlearnable Examples: Making Personal Data Unexploitable</strong> [<a href="https://openreview.net/pdf?id=iAmZUo0DxC0" target="_blank">PDF</a>] [<a href="https://github.com/HanxunH/Unlearnable-Examples">Code</a>] [<a href="https://www.technologyreview.com/2021/05/05/1024613/stop-ai-recognizing-your-face-selfies-machine-learning-facial-recognition-clearview/">MIT Technology Review</a>]<br>
                Hanxun Huang, Xingjun Ma#, Sarah Monazam Erfani, James Bailey, <strong>Yisen Wang#</strong><br>
                <em>International Conference on Learning Representations (<strong>ICLR 2021</strong>), 2021&nbsp;</em><span style="background-color:transparent;text-align:left">(</span><strong style="background-color:transparent;text-align:left"><font color="#ff0000">Spotlight, Top 4%</font></strong><span style="background-color:transparent;text-align:left">)</span>
</p>
</div>
</li>


<li>
<div align="justify">
<p><strong>Improving Adversarial Robustness via Channel-wise Activation Suppressing</strong> [<a href="https://arxiv.org/pdf/2103.08307.pdf" target="_blank">PDF</a>] [<a href="https://github.com/bymavis/CAS_ICLR2021">Code</a>]<br>
                Yang Bai*, Yuyuan Zeng*, Yong Jiang, Shu-Tao Xia#, Xingjun Ma, <strong>Yisen Wang#</strong><br>
                <em>International Conference on Learning Representations (<strong>ICLR 2021</strong>), 2021&nbsp;</em><span style="background-color:transparent;text-align:left">(</span><strong style="background-color:transparent;text-align:left"><font color="#ff0000">Spotlight, Top 4%</font></strong><span style="background-color:transparent;text-align:left">)</span>
</p>
</div>
</li>

<li>
<div align="justify">
<p><strong>Towards A Unified Understanding and Improving of Adversarial Transferability</strong> [<a href="https://openreview.net/pdf?id=X76iqnUbBjz" target="_blank">PDF</a>] [<a href="https://github.com/xherdan76/A-Unified-Approach-to-Interpreting-and-Boosting-Adversarial-Transferability">Code</a>]<br>
                Xin Wang*, Jie Ren*, Shuyun Lin, Xiangming Zhu, <strong>Yisen Wang</strong>, Quanshi Zhang<br>
                <em>International Conference on Learning Representations (<strong>ICLR 2021</strong>), 2021</em><br>
</p>
</div>
</li>

<li>
<div align="justify">
<p><strong>Adversarial Weight Perturbation Helps Robust Generalization</strong> [<a href="https://arxiv.org/pdf/2004.05884.pdf" target="_blank">PDF</a>] [<a href="https://github.com/csdongxian/AWP" target="_blank">Code</a>] [<a href="https://www.bilibili.com/video/BV1pt4y1Y7uU" target="_blank">NeurIPS MeetUp Video</a>]<br>
                Dongxian Wu, Shu-Tao Xia, <strong>Yisen Wang#</strong><br>
                <em>Neural Information Processing Systems (<strong>NeurIPS 2020</strong>), 2020&nbsp;</em><br>
</p>
</div>
</li>


<li>
<div align="justify">
<p><strong>Normalized Loss Functions for Deep Learning with Noisy Labels</strong> [<a href="https://arxiv.org/abs/2006.13554" target="_blank">PDF</a>] [<a href="https://github.com/HanxunHuangLemonBear/Active-Passive-Losses">Code</a>]<br>
                Xingjun Ma*, Hanxun Huang*, <strong>Yisen Wang#</strong>, Simone Romano, Sarah Erfani and James Bailey<br>
                <em>International Conference on Machine Learning (<strong>ICML 2020</strong>), 2020&nbsp;</em><br>
</p>
</div>
</li>


<li>
<div align="justify">
<p><strong>Improving Adversarial Robustness Requires Revisiting Misclassified Examples</strong> [<a href="https://openreview.net/pdf?id=rklOg6EFwS" target="_blank">PDF</a>] [<a href="https://github.com/YisenWang/MART">Code</a>]<br>
                <strong>Yisen Wang*</strong>, Difan Zou*, Jinfeng Yi, James Bailey, Xingjun Ma, Quanquan Gu<br>
                <em>International Conference on Learning Representations (<strong>ICLR 2020</strong>), Addis Ababa, Ethiopia, 2020&nbsp;</em><br>
</p>
</div>
</li>


<li>
<div align="justify">
<p><strong>Skip Connections Matter: On the Transferability of Adversarial Examples Generated with ResNets</strong> [<a href="https://openreview.net/pdf?id=BJlRs34Fvr" target="_blank">PDF</a>] [<a href="https://github.com/csdongxian/skip-connections-matter">Code</a>]<br>
                Dongxian Wu, <strong>Yisen Wang#</strong>, Shu-Tao Xia, James Bailey, Xingjun Ma<br>
                <em>International Conference on Learning Representations (<strong>ICLR 2020</strong>), Addis Ababa, Ethiopia, 2020&nbsp;</em>(<strong><font color="#ff0000">Spotlight</font></strong>)<br>
</p>
</div>
</li>

<li>
<div align="justify">
<p><strong>Adversarial Camouflage: Hiding Physical-World Attacks with Natural Styles</strong> [<a href="https://arxiv.org/abs/2003.08757" target="_blank">PDF</a>] [<a href="https://github.com/RjDuan/AdvCam-Hide-Adv-with-Natural-Styles">Code</a>]<br>
                Ranjie Duan, Xingjun Ma, <strong>Yisen Wang</strong>, James Bailey, Kai Qin, Yun Yang<br>
                <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR 2020</strong>), Seattle, USA, 2020&nbsp;</em><br>
</p>
</div>
</li>

<li>
<div align="justify">
<p><strong>Improving Query Efficiency of Black-box Adversarial Attack</strong> [<a href="https://arxiv.org/pdf/2009.11508.pdf" target="_blank">PDF</a>] [<a href="https://github.com/Sandy-Zeng/NPAttack">Code</a>]<br>
                Yang Bai*, Yuyuan Zeng*, Yong Jiang#, <strong>Yisen Wang#</strong>, Shu-Tao Xia, Weiwei Guo<br>
                <em>European Conference on Computer Vision (<strong>ECCV 2020</strong>), 2020&nbsp;</em><br>
</p>
</div>
</li>

<li>
<div align="justify">
<p><strong>Understanding Adversarial Attacks on Deep Learning Based Medical Image Analysis Systems</strong> [<a href="https://arxiv.org/pdf/1907.10456.pdf" target="_blank">PDF</a>] <br>
                Xingjun Ma, Yuhao Niu, Lin Gu, <strong>Yisen Wang</strong>, Yitian Zhao, James Bailey, Feng Lu <br>
                <em>Pattern Recognition (<strong>PR</strong>), 2020</em><br>
</p>
</div>
</li>


        <li>

<div align="justify">

<div align="justify">

<p><strong>On the Convergence and Robustness of Adversarial Training</strong> [<a href="http://proceedings.mlr.press/v97/wang19i/wang19i.pdf" target="_blank">PDF</a>] [<a href="https://github.com/YisenWang/dynamic_adv_training">Code</a>]<br>
                <strong>Yisen Wang*</strong>, Xingjun Ma*, James Bailey, Jinfeng Yi, Bowen Zhou, Quanquan Gu<br>
                <em>International Conference on Machine Learning (<strong>ICML 2019</strong>), Long Beach, USA, 2019&nbsp;</em>(<strong><font color="#ff0000">Long Talk</font></strong>)<br>
              </p>
            </div>

        </div>
</li>


        <li>


<div align="justify">

<p><strong>Symmetric Cross Entropy for Robust Learning with Noisy Labels</strong> [<a href="https://arxiv.org/abs/1908.06112" target="_blank">PDF</a>] [<a href="https://github.com/YisenWang/symmetric_cross_entropy_for_noisy_labels">Code</a>]<br>
                <strong>Yisen Wang*</strong>, Xingjun Ma*, Zaiyi Chen, Yuan Luo, Jinfeng Yi, James Bailey<br>
                <em>International Conference on Computer Vision (<strong>ICCV 2019</strong>), Seoul, Korea, 2019&nbsp;</em><br>
              </p>
            </div>

        </li>


        <li>

<div align="justify">

<div align="justify">

<p><strong>Hilbert-Based Generative Defense for Adversarial Examples</strong> [<a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Bai_Hilbert-Based_Generative_Defense_for_Adversarial_Examples_ICCV_2019_paper.pdf" target="_blank">PDF</a>]<br>
                Yang Bai*, Yan Feng*, <strong>Yisen Wang#</strong>, Shu-Tao Xia, Yong Jiang#<br>
                <em>International Conference on Computer Vision (<strong>ICCV 2019</strong>), Seoul, Korea, 2019&nbsp;</em><br>
              </p>
            </div>

        </div>
</li>

        <li>

<div align="justify">

<div align="justify">

<p><strong>Dirichlet Latent Variable Hierarchical Recurrent Encoder-Decoder in Dialogue Generation</strong> [<a href="https://www.aclweb.org/anthology/D19-1124.pdf" target="_blank">PDF</a>] [<a href="https://github.com/cloversjtu/dir-vhred">Code</a>] <br>
                Min Zeng, <strong>Yisen Wang#</strong>, Yuan Luo<br>
                <em>Conference on Empirical Methods in Natural Language Processing (<strong>EMNLP 2019</strong>), Hong Kong, China, 2019&nbsp;</em><br>
              </p>
            </div>

        </div>
</li>



        <li>

<div align="justify">

<div align="justify">

<p><strong>Learning Deep Hidden Nonlinear Dynamics from Aggregate Data </strong>[<a href="https://sites.google.com/site/csyisenwang/UAI2018.pdf?attredirects=0" target="_blank">PDF</a>][<a href="https://sites.google.com/site/csyisenwang/UAI2018-supp.pdf?attredirects=0" target="_blank">Appendix</a>] <br>
                <strong>Yisen Wang</strong>, Bo Dai, Lingkai Kong, Sarah Monazam Erfani, James Bailey, Hongyuan Zha<br>
                <em>Conference on Uncertainty in Artificial Intelligence (<strong>UAI 2018</strong>), California, USA, 2018</em> <br>
              </p>
            </div>
          </div>
        </li>

        <li>

<div align="justify">

<div align="justify">

<p><strong>Dimensionality-Driven Learning with Noisy Labels </strong>[<a href="https://sites.google.com/site/csyisenwang/ICML2018.pdf?attredirects=0" target="_blank">PDF</a>] [<a href="https://github.com/xingjunm/dimensionality-driven-learning">Code</a>] <br>
                Xingjun Ma*, <strong>Yisen Wang*</strong>, Michael E. Houle, Shuo Zhou, Sarah Monazam Erfani, Shu-Tao Xia, Sudanthi Wijewickrema, James Bailey<br>
                <em>International Conference on Machine Learning (<strong>ICML 2018</strong>), Stockholm, Sweden, 2018</em> (<strong><font color="#ff0000">Long Talk</font></strong>)<br>
              </p>
            </div>
          </div>
        </li>


        <li>

<div align="justify">

<div align="justify">

<p><strong>Iterative Learning with Open-set Noisy Labels </strong>[<a href="https://sites.google.com/site/csyisenwang/CVPR2018-iterative.pdf?attredirects=0" target="_blank">PDF</a>] [<a href="https://github.com/YisenWang/ONL">Code</a>] <br>
                <strong>Yisen Wang</strong>, Weiyang Liu, Xingjun Ma, James Bailey, Hongyuan Zha, Le Song, Shu-Tao Xia<br>
                <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR 2018</strong>), Salt Lake City, USA, 2018</em> (<strong><font color="#ff0000">Spotlight</font></strong>)<br>
              </p>
            </div>
          </div>
        </li>

        <li>

<div align="justify">

<div align="justify">

<p><strong>Decoupled Networks </strong>[<a href="https://sites.google.com/site/csyisenwang/CVPR2018-decouple.pdf?attredirects=0" target="_blank">PDF</a>] [<a href="https://github.com/wy1iu/DCNets">Code</a>] <br>
                Weiyang Liu, Zhen Liu, Zhiding Yu, Bo Dai, Rongmei Lin, <strong>Yisen Wang</strong>, James Rehg, Le Song<br>
                <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR 2018</strong>), Salt Lake City, USA, 2018</em> (<strong><font color="#ff0000">Spotlight</font></strong>)<br>
              </p>
            </div>
          </div>
        </li>

        <li>

<div align="justify">

<div align="justify">

<p><strong>Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality </strong> [<a href="https://sites.google.com/site/csyisenwang/ICLR2018.pdf?attredirects=0" target="_blank">PDF</a>] [<a href="https://github.com/xingjunm/lid_adversarial_subspace_detection">Code</a>]<br>
                Xingjun Ma, Bo Li, <strong>Yisen Wang</strong>, Sarah M. Erfani, Sudanthi Wijewickrema, Michael E. Houle, Grant Schoenebeck, Dawn Song, James Bailey<br>
<em>International Conference on Learning Representations (<strong>ICLR 2018</strong>), Vancouver, BC, Canada, 2018</em> (<strong><font color="#ff0000">Oral</font></strong>)<br>
              </p>
            </div>
          </div>
        </li>

<li>
<div align="justify">
<p><strong>A Novel Consistent Random Forest Framework: Bernoulli Random Forests</strong> [<a href="http://www.cse.fau.edu/~xqzhu/papers/TNN.Wang.2017.Forest.pdf" target="_blank">PDF</a>]<br>
                <strong>Yisen Wang</strong>, Shu-Tao Xia, Qingtao Tang, Jia Wu, Xingquan Zhu <br>
                <em>IEEE Transactions on Neural Networks and Learning Systems (<strong>TNNLS</strong>), 2017</em><br>
</p>
</div>
</li>

<li>
<div align="justify">
<p><strong>Link Sign Prediction by Variational Bayesian Probabilistic Matrix Factorization with Student-t Prior</strong> [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0020025517306655" target="_blank">PDF</a>]<br>
                <strong>Yisen Wang*</strong>, Fangbing Liu, Shu-Tao Xia, Jia Wu <br>
                <em>Information Sciences (<strong>IS</strong>), 2017</em><br>
</p>
</div>
</li>



        <li>

<div align="justify">

<div align="justify">

<p><strong>Residual convolutional CTC networks for automatic speech recognition </strong> [<a href="https://sites.google.com/site/csyisenwang/ASR-CTC.pdf?attredirects=0" target="_blank">PDF</a>]<br>
                <strong>Yisen Wang*</strong>, Xuejiao Deng*, Songpai Pu, Zhiheng Huang<br>
                <em>Arxiv Technical Report, 2017</em> <br>
              </p>
            </div>
          </div>
        </li>

        <li>

<div align="justify">

<div align="justify">

<p><strong>Unbiased Multivariate Correlation Analysis </strong> [<a href="https://sites.google.com/site/csyisenwang/AAAI2017.pdf?attredirects=0" target="_blank">PDF</a>] [<a href="https://sites.google.com/site/csyisenwang/AAAI2017-supp.pdf?attredirects=0" target="_blank">Appendix</a>]<br>
                <strong>Yisen Wang</strong>, Simone Romano, Nguyen Vinh, James Bailey, Xingjun Ma, Shu-Tao Xia<br>
                <em>AAAI Conference on Artificial Intelligence (<strong>AAAI 2017</strong>), San Francisco, California, USA, 2017.</em> (<strong><font color="#ff0000">Oral</font></strong>)<br>
              </p>
            </div>
          </div>
        </li>

            <li>

<div align="justify">

<div align="justify">

<p><strong>Unifying Attribute Splitting Criteria of Decision Trees by Tsallis Entropy </strong> [<a href="https://sites.google.com/site/csyisenwang/ICASSP2017.pdf?attredirects=0" target="_blank">PDF</a>]<br>
                    <strong>Yisen Wang</strong>, Shu-Tao Xia <br>
                    <em>IEEE International Conference on Acoustics, Speech and Signal Processing (<strong>ICASSP 2017</strong>), New Orleans, USA, 2017.&nbsp;</em></p>
                </div>
              </div>
            </li>

             <li>

<div align="justify">

<div align="justify">

<p><strong>Student-t Process Regression with Student-t Likelihood </strong> [<a href="https://sites.google.com/site/csyisenwang/IJCAI2017-tprocess.pdf?attredirects=0" target="_blank">PDF</a>]<br>
                    Qingtao Tang, Li Niu, <strong>Yisen Wang</strong>, Tao Dai, Wangpeng An, Jianfei Cai, Shu-Tao Xia <br>
                    <em>International Joint Conference on Artificial Intelligence (<strong>IJCAI 2017</strong>), Melbourne, Australia, 2017. </em>(<strong><font color="#ff0000">Oral</font></strong>) </p>
                </div>
              </div>
            </li>

             <li>

<div align="justify">

<div align="justify">

<p><strong>Robust Survey Aggregation with Student-t Distribution and Sparse Representation </strong> [<a href="https://sites.google.com/site/csyisenwang/IJCAI2017-survey.pdf?attredirects=0" target="_blank">PDF</a>]<br>
                    Qingtao Tang, Tao Dai, Li Niu, <strong>Yisen Wang</strong>,  Shu-Tao Xia, Jianfei Cai <br>
                    <em>International Joint Conference on Artificial Intelligence (<strong>IJCAI 2017</strong>), Melbourne, Australia, 2017. </em>(<strong><font color="#ff0000">Oral</font></strong>) </p>
                </div>
              </div>
            </li>

            <li>

<div align="justify">

<div align="justify">

<p><strong>Bernoulli Random Forests: Closing the Gap between Theoretical Consistency and Empirical Soundness </strong> [<a href="https://sites.google.com/site/csyisenwang/IJCAI2016.pdf?attredirects=0" target="_blank">PDF</a>]<br>
                    <strong>Yisen Wang</strong>, Qingtao Tang, Shu-Tao Xia, Jia Wu, Xingquan Zhu <br>
                    <em>International Joint Conference on Artificial Intelligence (<strong>IJCAI 2016</strong>), New York, USA, 2016. </em>(<strong><font color="#ff0000">Oral</font></strong>) </p>
                </div>
              </div>
            </li>


             <li>

<div align="justify">

<div align="justify">

<p><strong>Student-t Process Regression with Dependent Student-t Noise </strong> [<a href="https://sites.google.com/site/csyisenwang/ECAI2016.pdf?attredirects=0" target="_blank">PDF</a>]<br>
                    Qingtao Tang, <strong>Yisen Wang</strong>, Shu-Tao Xia <br>
                    <em>European Conference on Artificial Intelligence (<strong>ECAI 2016</strong>), Hague, Netherlands, 2016. </em>(<strong><font color="#ff0000">Oral</font></strong>) </p>
                </div>
              </div>
            </li>


        </ol>
</td>
      </tr>
    </tbody>
  </table>


<hr>


<p align="justify"><span><span style="font-size:22pt"><b><span style="font-family:Monotype Corsiva;COLOR:green"><a name="Bio"></a><span>Academic Service</span></span></b></span></span><br>

</p>
<ul>
<li><span style="font-family:Monotype Corsiva">Associate Editor:</span>&nbsp;Neurocomputing </li>
<li><span style="font-family:Monotype Corsiva">Journal Reviewer:</span>&nbsp;TPAMI, TIT, TIFS, TNNLS, TKDD, etc. </li>
<li><span style="font-family:Monotype Corsiva">Conference Area Chair / Senior Program Committee:</span>&nbsp;NeurIPS 2021, IJCAI 2021, ACML 2021. </li>
<li><span style="font-family:Monotype Corsiva">Conference Program Committee:</span>&nbsp;NeurIPS, ICML, ICLR, CVPR, ICCV, ECCV, AAAI, IJCAI, etc. </li>
</ul>


<p align="justify"><span><span style="font-size:22pt"><b><span style="font-family:Monotype Corsiva;COLOR:green"><a name="Bio"></a><span>Talks</span></span></b></span></span><br>
</p>

<ul>

<li>
<div align="justify">
<p><strong>Rethinking the Min-max Problem for Adversarial Robustness</strong> [<a href="https://courses.grainger.illinois.edu/cs498lb1/sp2021/" target="_blank">Event</a>]
    [<a href="https://yisenwang.github.io/talks/Rethinking%20the%20min-max%20Problem%20for%20Adversarial%20Robustness@UIUC.pdf" target="_blank">Slides</a>] <br>
                <em>Guest Lecture for CS 498@UIUC</em>, Mar 2021.
</p>
</div>
</li>


<li>
<div align="justify">
<p><strong>Adversarial Machine Learning on Robustness, Privacy, and Architecture</strong> [<a href="https://event.baai.ac.cn/activities/131" target="_blank">Event</a>]
    [<a href="https://mp.weixin.qq.com/s/-lzPJFRmRhgqfJp4ckqMCw" target="_blank">Media</a>] <br>
                <em>BAAI Seminar Adversarial Machine Learning Session</em>, Keynote Talk &amp; Organizer, Feb 2021.
</p>
</div>
</li>

<li>
<div align="justify">
<p><strong>Adversarial Machine Learning and Beyond</strong> [<a href="https://www.bilibili.com/video/BV1Bt4y1z7Su" target="_blank">Video</a>]<br>
                <em>Key Laboratory of Machine Perception (MOE) Annual Meeting, Peking University</em>, Invited Talk &amp; Organizer, Jan 2021.
</p>
</div>
</li>

<li>
<div align="justify">
<p><strong>Towards Trustworthy Machine Learning</strong> [<a href="http://www.lamda.nju.edu.cn/news_201109.ashx" target="_blank">Event</a>]<br>
                <em>LAMDA Lab, Nanjing University</em>, Invited Talk, Nov 2020.
</p>
</div>
</li>

<li>
<div align="justify">
<p><strong>The Design of Robust Loss Function for Learning with Noisy Label</strong> [<a href="http://csee.hnu.edu.cn/ccdm2020/xsztlt.html" target="_blank">Event</a>]<br>
                <em>China Conference on Data Mining (CCDM) Workshop</em>, Invited Talk, Aug 2020.
</p>
</div>
</li>

</ul>

<hr>

<p align="justify"><span><span style="font-size:22pt"><b><span style="font-family:Monotype Corsiva;COLOR:green"><a name="Bio"></a><span>Awards</span></span></b></span></span><br>


  </p>
<ul>

    <li><a href="http://scholarship.baidu.com/" target="_blank">Baidu Scholarship</a> (only 10 world-wide per year)&nbsp;</li>
    <li><a href="http://www.acmturc.com/2020/cn/doctoral_thesis_award.html" target="_blank">ACM China Doctoral Dissertation Nomination Award</a> (only 5 nation-wide per year)</li>
    <li>Tsinghua University Outstanding Doctoral Dissertation Award</li>
    <li><a href="https://www.msra.cn/zh-cn/connections/academic-programs/fellows" target="_blank">Microsoft Research Fellowship Nomination Award</a></li>
    <li>Best Paper Award at 9th International Doctoral Forum (Hong Kong)</li>
    <li>National Scholarship for PhD Student</li>
    <li>Lixin Tang Scholarship of Tsinghua University</li>
    <li>Top 10 Undergraduate Excellence Award (only 10 awardees university-wide per year)</li>
    <li>Meritorious Winner (First Prize) of MCM: The Mathematical Contest in Modeling</li>
    <li>National Scholarship for Undergraduate Student</li>
  </ul>

<hr>
</blockquote>
